{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "f1_loss_OR0.4_t3_v1110.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Qr7go0FwXOPO",
        "KW15dZJWWhWg",
        "67CFvVVVsLLq",
        "x8f5cOY5Qy3k",
        "Ixe_J4XHHqT7",
        "u8RtmEpg1Jhg",
        "tgP8YfOLYGm3",
        "QOEKq15SHjIG",
        "cwHC7Ef_8e3Q",
        "6kudlYMmrWwQ",
        "91gBE3c8UPLO",
        "YbQxj4wvVpV9",
        "uygmX0FhnxOC",
        "16w2BwEXPdUL",
        "0CqSHnJ0U1ed",
        "opyctmT7VDHX",
        "H81HTrIvVNjf",
        "sEKkJs2LeFLq",
        "NtXn0WWZeKsG",
        "dy1PndkpUmFz",
        "gtNjIpq2SXdL",
        "M79JA4nieZ7F",
        "J8gZiAKDeKgG",
        "6cr3qhn4eeD5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDYvYCdxW3YL",
        "cellView": "form"
      },
      "source": [
        "#@markdown # Installation\n",
        "\n",
        "%%bash\n",
        "pip3 install -qU tensorflow-datasets\n",
        "pip3 install -qU tensorflow-addons --no-deps\n",
        "pip3 install -qU jupyter-tensorboard\n",
        "pip3 install -qU --pre efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRbslncgoAvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "079f49a4-aa48-4887-8a9c-6fdbed11167d"
      },
      "source": [
        "#@markdown # Prepare a package for custom dataset.\n",
        "\n",
        "!pip install -Uq tensorflow_datasets\n",
        "\n",
        "def _snake_to_camel(word):\n",
        "  return ''.join(x.capitalize() or '_' for x in word.split('_'))\n",
        "\n",
        "NAME_DATASET = 'aigc1110v1' #@param ['aigc1109v2', 'aigc1110v1'] {type: 'string'}\n",
        "NAME_DATASET_CAMEL = _snake_to_camel(NAME_DATASET)\n",
        "\n",
        "import os\n",
        "if not os.path.exists(NAME_DATASET):\n",
        "  !tfds new $NAME_DATASET\n",
        "\n",
        "_code = f'''\n",
        "\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "\n",
        "from absl import logging\n",
        "from xml.etree import ElementTree\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.io import decode_jpeg, encode_jpeg, extract_jpeg_shape\n",
        "\n",
        "_DESCRIPTION = \"\"\"\n",
        "Trash datasets made by IRIS Lab at 2020/10/19.\n",
        "\"\"\"\n",
        "\n",
        "_OBJECT_LABELS = [\n",
        "    'paper',\n",
        "    'paperpack',\n",
        "    'can',      \n",
        "    'glass',    \n",
        "    'pet',      \n",
        "    'plastic',  \n",
        "    'vinyl',    \n",
        "]\n",
        "\n",
        "class {NAME_DATASET_CAMEL}(tfds.core.GeneratorBasedBuilder):\n",
        "  \"\"\"DatasetBuilder for aigc_201019 dataset.\"\"\"\n",
        "\n",
        "  VERSION = tfds.core.Version('1.0.0')\n",
        "  RELEASE_NOTES = {{\n",
        "      '1.0.0': 'Initial release.',\n",
        "  }}\n",
        "  MANUAL_DOWNLOAD_INSTRUCTIONS = \"\"\"\\\n",
        "  manual_dir should contain two files:  {NAME_DATASET}_train.tar and\n",
        "  {NAME_DATASET}_valid.tar'\n",
        "  \"\"\"\n",
        "\n",
        "  def _info(self) -> tfds.core.DatasetInfo:\n",
        "    \"\"\"Returns the dataset metadata.\"\"\"\n",
        "    annotations = {{\n",
        "        'label' : tfds.features.ClassLabel(names=_OBJECT_LABELS),\n",
        "        'bbox'  : tfds.features.BBoxFeature()\n",
        "    }}\n",
        "    return tfds.core.DatasetInfo(\n",
        "        builder=self,\n",
        "        description=_DESCRIPTION,\n",
        "        features=tfds.features.FeaturesDict({{\n",
        "            'image' : tfds.features.Image(encoding_format='jpeg'),\n",
        "            'objects': tfds.features.Sequence(annotations),\n",
        "            'image_id': tfds.features.Text(),\n",
        "        }}),\n",
        "        # If there's a common (input, target) tuple from the\n",
        "        # features, specify them here. They'll be used if\n",
        "        # `as_supervised=True` in `builder.as_dataset`.\n",
        "        supervised_keys=None,  # e.g. ('image', 'label')\n",
        "    )\n",
        "\n",
        "  def _split_generators(self, dl_manager: tfds.download.DownloadManager):\n",
        "    \"\"\"Returns SplitGenerators.\"\"\"\n",
        "    train_path = os.path.join(dl_manager.manual_dir, '{NAME_DATASET}_train.tar')\n",
        "    valid_path = os.path.join(dl_manager.manual_dir, '{NAME_DATASET}_validation.tar')\n",
        "\n",
        "    return [\n",
        "        tfds.core.SplitGenerator(\n",
        "            name=tfds.Split.TRAIN,\n",
        "            gen_kwargs={{\n",
        "                'archive': dl_manager.iter_archive(train_path),\n",
        "                're_archive': dl_manager.iter_archive(train_path)\n",
        "            }},\n",
        "        ),\n",
        "        tfds.core.SplitGenerator(\n",
        "            name=tfds.Split.VALIDATION,\n",
        "            gen_kwargs={{\n",
        "                'archive': dl_manager.iter_archive(valid_path),\n",
        "                're_archive': dl_manager.iter_archive(valid_path)\n",
        "            }},\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "  def _parse_xml(self, byte_string):\n",
        "    root_elem = ElementTree.parse(byte_string)\n",
        "    obj_elems = root_elem.iter(tag='object')\n",
        "\n",
        "    annotation = []\n",
        "    for obj_elem in obj_elems:\n",
        "      obj_dict = dict()\n",
        "      label = obj_elem.find('name').text\n",
        "      bbox_elem = obj_elem.find('bndbox')\n",
        "      bbox = [int(bbox_elem.find('ymin').text),\n",
        "              int(bbox_elem.find('xmin').text),\n",
        "              int(bbox_elem.find('ymax').text),\n",
        "              int(bbox_elem.find('xmax').text)]\n",
        "      obj_dict['label'] = label\n",
        "      obj_dict['bbox_raw'] = bbox\n",
        "      annotation.append(obj_dict)\n",
        "    return annotation\n",
        "\n",
        "  def _parse_json(self, byte_string):\n",
        "    byte_string = byte_string.getvalue()\n",
        "    _label_conversion_tbl = {{\n",
        "        'c_1': 'paper',\n",
        "        'c_2': 'paperpack',\n",
        "        'c_3': 'can',\n",
        "        'c_4': 'glass',\n",
        "        'c_5': 'pet',\n",
        "        'c_6': 'plastic',\n",
        "        'c_7': 'vinyl',\n",
        "    }}\n",
        "    annot_dict = json.loads(byte_string)\n",
        "    objects = annot_dict['object']\n",
        "    annotation = []\n",
        "    for obj in objects:\n",
        "      obj_dict = dict()\n",
        "      obj_dict['label'] = _label_conversion_tbl[obj['label']]\n",
        "      box = obj['box']\n",
        "      # (xmin, ymin, xmax, ymax) -> (ymin, xmin, ymax, xmax)\n",
        "      obj_dict['bbox_raw'] = [box[1], box[0], box[3], box[2]]\n",
        "      annotation.append(obj_dict)\n",
        "    return annotation\n",
        "\n",
        "  def _build_relative_bbox(self, absolute_bbox, shape):\n",
        "    height  = shape[0]\n",
        "    width = shape[1]\n",
        "    relative_bbox = []\n",
        "    relative_bbox.append(absolute_bbox[0] / height)\n",
        "    relative_bbox.append(absolute_bbox[1] / width)\n",
        "    relative_bbox.append(absolute_bbox[2] / height)\n",
        "    relative_bbox.append(absolute_bbox[3] / width)\n",
        "    return relative_bbox\n",
        "\n",
        "\n",
        "  def _convert_png_to_jpeg(self, png_image_bytes):\n",
        "    return io.BytesIO(tfds.core.utils.png_to_jpeg(png_image_bytes))\n",
        "\n",
        "  def _generate_examples(self, archive, re_archive):\n",
        "    \"\"\"Yields examples.\"\"\"\n",
        "    error_list = []\n",
        "    all_annotations = dict()\n",
        "\n",
        "    # Search every annotation files.\n",
        "    for fpath, fobj in archive:\n",
        "      prefix, ext = os.path.splitext(fpath)\n",
        "      image_id = prefix.split(os.path.sep)[-1]\n",
        "      if ext == '.xml' or ext == '.json':\n",
        "        try:\n",
        "          fobj_mem = io.BytesIO(fobj.read())\n",
        "          annotations = self._parse_xml(fobj_mem) if ext =='.xml' else self._parse_json(fobj_mem)\n",
        "          all_annotations[image_id] = annotations\n",
        "        except:\n",
        "          error_list.append(image_id)\n",
        "          logging.warning(\n",
        "              f\" Error occurs during parsing '{{fpath}}'. \"\n",
        "               \"Skip this file.\"\n",
        "          )\n",
        "\n",
        "    for fpath, fobj in re_archive:\n",
        "      prefix, ext = os.path.splitext(fpath)\n",
        "      if ext == '.xml' or ext == '.json': continue\n",
        "      image_id = prefix.split(os.path.sep)[-1]\n",
        "      fobj_mem = io.BytesIO(fobj.read())\n",
        "      if ext in ['.jpeg', '.jpg', '.JPEG', '.JPG']:\n",
        "        if image_id in error_list: continue\n",
        "        image = fobj_mem\n",
        "      elif ext in ['png', 'PNG']:\n",
        "        if image_id in error_list: continue\n",
        "        logging.info(\n",
        "            f\" Convert '{{fpath}}' to PNG file.\"\n",
        "        )\n",
        "        image = self._convert_png_to_jpeg(fobj_mem)\n",
        "      else:\n",
        "        logging.warning((\n",
        "            f' {{ext}} format is not expected.'\n",
        "            f' {{fpath}} made a error.'))\n",
        "        \n",
        "      _, fname = os.path.split(fpath)\n",
        "      try:\n",
        "        annotations = all_annotations[image_id]\n",
        "      except:\n",
        "        logging.warning(\n",
        "            f\" Error occurs. There is no annotation file for '{{fpath}}'.\"\n",
        "             \"Skip this file.\"\n",
        "        )\n",
        "        continue\n",
        "      for obj in annotations:\n",
        "        try:  # There are images which raise error with 'extract_jpeg_shape'.\n",
        "          shape = extract_jpeg_shape(image.getvalue()).numpy()\n",
        "        except:\n",
        "          image = decode_jpeg(image.getvalue())\n",
        "          shape = image.shape\n",
        "          image = io.BytesIO(encode_jpeg(image).numpy())\n",
        "\n",
        "        bbox = self._build_relative_bbox(obj['bbox_raw'], shape)\n",
        "        obj['bbox'] = tfds.features.BBox(*bbox)\n",
        "        del obj['bbox_raw']\n",
        "      record = {{\n",
        "          'image': image,\n",
        "          'objects': annotations,\n",
        "          'image_id': image_id,\n",
        "      }} \n",
        "      yield fname, record\n",
        "\n",
        "'''\n",
        "\n",
        "with open(f'{NAME_DATASET}/{NAME_DATASET}.py', 'w') as f:\n",
        "  f.write(_code)\n",
        "  \n",
        "import importlib\n",
        "_ = importlib.import_module(NAME_DATASET)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-16 06:06:15.014801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Dataset generated at /content/aigc1110v1\n",
            "You can start searching `TODO(aigc1110v1)` to complete the implementation.\n",
            "Please check https://www.tensorflow.org/datasets/add_dataset for additional details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhgfIET5ZIhk",
        "cellView": "form"
      },
      "source": [
        "#@markdown # **Hyperparameters & Presets**\n",
        "#@markdown * BATCH_SIZE_PER_REPLICA is recommend to being multiples of 64.\n",
        "#@markdown * RAND_AUGMENT - [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/pdf/1909.13719)\n",
        "#@markdown * USE_BFLOAT16 - Wheter to use [mixed precision](https://www.tensorflow.org/guide/mixed_precision).\n",
        " \n",
        "_input_sizes = {\n",
        "  'B0': 224,\n",
        "  'B1': 240,\n",
        "  'B2': 260,\n",
        "  'B3': 300,\n",
        "  'B4': 380,\n",
        "  'B5': 456,\n",
        "  'B6': 528,\n",
        "  'B7': 600,\n",
        "}\n",
        "\n",
        "#@markdown ## **Tensorboard & Checkpoints**\n",
        "SHOW_TENSORBOARD = False #@param {type: 'boolean'}\n",
        "WRITE_TB = True #@param {type: 'boolean'}\n",
        "STORE_CKPT = True #@param {type: 'boolean'}\n",
        "TOKEN = 'f1_loss_OR0.4_t3_v1110' #@param {type: 'string'}\n",
        "\n",
        "#@markdown ## **Training Setting**\n",
        "MODEL_CODE = 'B7' #@param ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "INPUT_SIZE = _input_sizes[MODEL_CODE]\n",
        "RESIZE_SIZE = int(INPUT_SIZE * (1/0.875))\n",
        "EPOCHS =  150#@param {type: 'integer'}\n",
        "BATCH_SIZE_PER_REPLICA = 64 #@param {type: \"slider\", min:64, max:256, step:64}\n",
        "FIX_INPUT_SIZE = 660 #@param {type: 'integer'}\n",
        "FIX_RESIZE_SIZE = int(FIX_INPUT_SIZE * (1/0.875))\n",
        "#@markdown ## **Loss & Optimizer**\n",
        "LOSS_FUNC = 'f1_loss' #@param [\"binary_crossentropy\", \"f1_loss\", \"categorical_crossentropy\", \"hybrid\"]\n",
        "OPTIMIZER = 'SGD' #@param [\"SGD\", \"RMSprop\", \"Adam\"]\n",
        "LR_BASE_VALUE = 0.1 #@param {type: 'number'}\n",
        "LR_DECAY_TYPE = 'cosine' #@param [\"exponential\", \"cosine\", \"constant\", \"poly\"]\n",
        "LR_DECAY_EPOCHS = 10 #@param {type: 'number'}\n",
        "LR_WARMUP_EPOCHS = 5 #@param {type: 'number'}\n",
        "LABEL_SMOOTHING = 0.1 #@param {type: 'number'}\n",
        "#@markdown ## **Augmentation**\n",
        "RAND_AUGMENT = True #@param {type: 'boolean'}\n",
        "RA_NUM_LAYERS = 2 #@param {type: \"slider\", min:1, max:3, step:1}\n",
        "RA_MAGNITUDE = 13 #@param {type: \"slider\", min:5, max:30, step:1}\n",
        "USE_BFLOAT16 = True #@param {type: 'boolean'}\n",
        "#@markdown ## **VM & GCS Setting**\n",
        "BUCKET = 'gs://iris-us' #@param [\"gs://iris-us\"]\n",
        "GCP_VM = False #@param {type: 'boolean'}\n",
        "GCP_TPU_NAME = '' #@param {type: 'string'}\n",
        "#@markdown ## **Finetuning Options**\n",
        "OPEN_RATIO =  0.4 #@param {type: 'slider', min: 0, max: 1.0, step: 0.1}\n",
        "\n",
        "SEED = 8047\n",
        "EPOCH = 1\n",
        "\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# Check current region.\n",
        "_regions = {\n",
        "    'us': 'America',\n",
        "    'eu': 'Europe',\n",
        "}\n",
        "res = requests.get('http://ipinfo.io')\n",
        "info = json.loads(res.text)\n",
        "region = info['timezone'].split('/')[0]\n",
        "if region != _regions[BUCKET.split('-')[-1]]:\n",
        "  raise Exception('[WARNING] Region setting is wrong.')\n",
        "\n",
        "# Set GCS TFDS path.\n",
        "DATA_DIR = os.path.join(BUCKET, 'tfds_datasets')\n",
        "\n",
        "# Checkpoint path.\n",
        "CKPT_PATH = os.path.join(BUCKET, 'ai', 'checkpoints', TOKEN)\n",
        "\n",
        "# Set TPU name. (None means auto-detection)\n",
        "TPU_NAME = None\n",
        "if GCP_VM:\n",
        "  TPU_NAME = GCP_TPU_NAME\n",
        "\n",
        "OBJECT_LABELS = [\n",
        "    'paper',\n",
        "    'paperpack',\n",
        "    'can',      \n",
        "    'glass',    \n",
        "    'pet',      \n",
        "    'plastic',  \n",
        "    'vinyl',    \n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS4er99FLSBX",
        "cellView": "form"
      },
      "source": [
        "#@markdown  # Import packages\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import inspect\n",
        "import functools\n",
        "\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "import efficientnet.tfkeras as efn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "if not GCP_VM:\n",
        "  import tensorflow_gcs_config as tgc\n",
        "\n",
        "if USE_BFLOAT16:\n",
        "  policy = mixed_precision.Policy('mixed_bfloat16')\n",
        "  mixed_precision.set_policy(policy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDuynJRQsGhx"
      },
      "source": [
        "## TPU & GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KURo_-2DWdZV"
      },
      "source": [
        "def initialize():\n",
        "  if not GCP_VM:\n",
        "    key_path = 'my_key.json'\n",
        "\n",
        "    key_data =  {\n",
        "      # GCS Auth key data.\n",
        "    }\n",
        "    \n",
        "    with open(key_path, mode='w') as f:\n",
        "      json.dump(key_data, f)\n",
        "  \n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS']=key_path\n",
        "\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_NAME)\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "  if not GCP_VM:\n",
        "    tgc.configure_gcs_from_colab_auth()\n",
        "\n",
        "  return strategy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr7go0FwXOPO"
      },
      "source": [
        "## Initialize systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ysjMbkWx6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf595bec-383d-40cc-c114-51e297bc2bb8"
      },
      "source": [
        "strategy = initialize()\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "INITIAL_LR = LR_BASE_VALUE * (BATCH_SIZE / 256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.77.58.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.77.58.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW15dZJWWhWg"
      },
      "source": [
        "# **Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67CFvVVVsLLq"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8f5cOY5Qy3k"
      },
      "source": [
        "### RandAugment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqBKJ40AIdV"
      },
      "source": [
        "def autocontrast(image):\n",
        "  \"\"\"Implements Autocontrast function from PIL using TF ops.\n",
        "  Args:\n",
        "    image: A 3D uint8 tensor.\n",
        "  Returns:\n",
        "    The image after it has had autocontrast applied to it and will be of type\n",
        "    uint8.\n",
        "  \"\"\"\n",
        "\n",
        "  def scale_channel(image):\n",
        "    \"\"\"Scale the 2D image using the autocontrast rule.\"\"\"\n",
        "    # A possibly cheaper version can be done using cumsum/unique_with_counts\n",
        "    # over the histogram values, rather than iterating over the entire image.\n",
        "    # to compute mins and maxes.\n",
        "    lo = tf.cast(tf.reduce_min(image), 'float32')\n",
        "    hi = tf.cast(tf.reduce_max(image), 'float32')\n",
        "\n",
        "    # Scale the image, making the lowest value 0 and the highest value 255.\n",
        "    def scale_values(im):\n",
        "      scale = 255.0 / (hi - lo)\n",
        "      offset = -lo * scale\n",
        "      im = tf.cast(im, 'float32') * scale + offset\n",
        "      im = tf.clip_by_value(im, 0.0, 255.0)\n",
        "      return tf.cast(im, tf.uint8)\n",
        "\n",
        "    result = tf.cond(hi > lo, lambda: scale_values(image), lambda: image)\n",
        "    return result\n",
        "\n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image[:, :, 0])\n",
        "  s2 = scale_channel(image[:, :, 1])\n",
        "  s3 = scale_channel(image[:, :, 2])\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        "\n",
        "def equalize(image):\n",
        "  return tfa.image.equalize(image)\n",
        "\n",
        "def invert(image):\n",
        "  return 255 - image\n",
        "\n",
        "def wrap(image):\n",
        "  return tfa.image.utils.wrap(image)\n",
        "\n",
        "def unwrap(image, replace):\n",
        "  return tfa.image.utils.unwrap(image, replace)\n",
        "\n",
        "def rotate(image, degrees, replace):\n",
        "  \"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n",
        "  Args:\n",
        "    image: An image Tensor of type uint8.\n",
        "    degrees: Float, a scalar angle in degrees to rotate all images by. If\n",
        "      degrees is positive the image will be rotated clockwise otherwise it will\n",
        "      be rotated counterclockwise.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels caused by\n",
        "      the rotate operation.\n",
        "  Returns:\n",
        "    The rotated version of image.\n",
        "  \"\"\"\n",
        "  # Convert from degrees to radians.\n",
        "  degrees_to_radians = math.pi / 180.0\n",
        "  radians = degrees * degrees_to_radians\n",
        "\n",
        "  # In practice, we should randomize the rotation degrees by flipping\n",
        "  # it negatively half the time, but that's done on 'degrees' outside\n",
        "  # of the function.\n",
        "  image = tfa.image.rotate(wrap(image), radians)\n",
        "  return unwrap(image, replace)\n",
        "\n",
        "def blend(image1, image2, factor):\n",
        "  return tf.cast(tfa.image.blend(image1, image2, factor), 'uint8')\n",
        "\n",
        "def posterize(image, bits):\n",
        "  \"\"\"Equivalent of PIL Posterize.\"\"\"\n",
        "  shift = 8 - bits\n",
        "  return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
        "\n",
        "def solarize(image, threshold=128):\n",
        "  \"\"\" For each pixel in the image, select the pixel\n",
        "      if the value is less than the threshold.\n",
        "      Otherwise, subtract 255 from the pixel.\n",
        "  \"\"\"\n",
        "  return tf.where(image < threshold, image, 255 - image)\n",
        "\n",
        "def color(image, factor):\n",
        "  \"\"\"Equivalent of PIL Color.\"\"\"\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
        "  return blend(degenerate, image, factor)\n",
        "\n",
        "def contrast(image, factor):\n",
        "  \"\"\"Equivalent of PIL Contrast.\"\"\"\n",
        "  degenerate = tf.image.rgb_to_grayscale(image)\n",
        "  # Cast before calling tf.histogram.\n",
        "  degenerate = tf.cast(degenerate, tf.int32)\n",
        "\n",
        "  # Compute the grayscale histogram, then compute the mean pixel value,\n",
        "  # and create a constant image size of that value.  Use that as the\n",
        "  # blending degenerate target of the original image.\n",
        "  hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n",
        "  mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.0\n",
        "  degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n",
        "  degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n",
        "  return blend(degenerate, image, factor)\n",
        "\n",
        "def brightness(image, factor):\n",
        "  \"\"\"Equivalent of PIL Brightness.\"\"\"\n",
        "  degenerate = tf.zeros_like(image)\n",
        "  return blend(degenerate, image, factor)\n",
        "\n",
        "def sharpness(image, factor):\n",
        "  return tfa.image.sharpness(image, factor)\n",
        "\n",
        "def shear_x(image, level, replace):\n",
        "  return tfa.image.shear_x(image, level, replace)\n",
        "\n",
        "def shear_y(image, level, replace):\n",
        "  return tfa.image.shear_y(image, level, replace)\n",
        "\n",
        "def translate_x(image, pixels, replace):\n",
        "  \"\"\"Equivalent of PIL Translate in X dimension.\"\"\"\n",
        "  image = tfa.image.translate(wrap(image), [-pixels, 0])\n",
        "  return unwrap(image, replace)\n",
        "\n",
        "\n",
        "def translate_y(image, pixels, replace):\n",
        "  \"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"\n",
        "  image = tfa.image.translate(wrap(image), [0, -pixels])\n",
        "  return unwrap(image, replace)\n",
        "\n",
        "def cutout(image, pad_size, replace=0):\n",
        "  \"\"\"Apply cutout (https://arxiv.org/abs/1708.04552) to image.\n",
        "  This operation applies a (2*pad_size x 2*pad_size) mask of zeros to\n",
        "  a random location within `img`. The pixel values filled in will be of the\n",
        "  value `replace`. The located where the mask will be applied is randomly\n",
        "  chosen uniformly over the whole image.\n",
        "  Args:\n",
        "    image: An image Tensor of type uint8.\n",
        "    pad_size: Specifies how big the zero mask that will be generated is that\n",
        "      is applied to the image. The mask will be of size\n",
        "      (2*pad_size x 2*pad_size).\n",
        "    replace: What pixel value to fill in the image in the area that has\n",
        "      the cutout mask applied to it.\n",
        "  Returns:\n",
        "    An image Tensor that is of type uint8.\n",
        "  \"\"\"\n",
        "  image_height = tf.shape(image)[0]\n",
        "  image_width = tf.shape(image)[1]\n",
        "\n",
        "  # Sample the center location in the image where the zero mask will be applied.\n",
        "  cutout_center_height = tf.random.uniform(\n",
        "      shape=[], minval=0, maxval=image_height,\n",
        "      dtype=tf.int32)\n",
        "\n",
        "  cutout_center_width = tf.random.uniform(\n",
        "      shape=[], minval=0, maxval=image_width,\n",
        "      dtype=tf.int32)\n",
        "\n",
        "  lower_pad = tf.maximum(0, cutout_center_height - pad_size)\n",
        "  upper_pad = tf.maximum(0, image_height - cutout_center_height - pad_size)\n",
        "  left_pad = tf.maximum(0, cutout_center_width - pad_size)\n",
        "  right_pad = tf.maximum(0, image_width - cutout_center_width - pad_size)\n",
        "\n",
        "  cutout_shape = [image_height - (lower_pad + upper_pad),\n",
        "                  image_width - (left_pad + right_pad)]\n",
        "  padding_dims = [[lower_pad, upper_pad], [left_pad, right_pad]]\n",
        "  mask = tf.pad(\n",
        "      tf.zeros(cutout_shape, dtype=image.dtype),\n",
        "      padding_dims, constant_values=1)\n",
        "  mask = tf.expand_dims(mask, -1)\n",
        "  mask = tf.tile(mask, [1, 1, 3])\n",
        "  image = tf.where(\n",
        "      tf.equal(mask, 0),\n",
        "      tf.ones_like(image, dtype=image.dtype) * replace,\n",
        "      image)\n",
        "  return image\n",
        "\n",
        "def solarize_add(image, addition=0, threshold=128):\n",
        "  # For each pixel in the image less than threshold\n",
        "  # we add 'addition' amount to it and then clip the\n",
        "  # pixel value to be between 0 and 255. The value\n",
        "  # of 'addition' is between -128 and 128.\n",
        "  added_image = tf.cast(image, tf.int64) + addition\n",
        "  added_image = tf.cast(tf.clip_by_value(added_image, 0, 255), tf.uint8)\n",
        "  return tf.where(image < threshold, added_image, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cTw388z-Jm4"
      },
      "source": [
        "_MAX_LEVEL = 10.\n",
        "\n",
        "NAME_TO_FUNC = {\n",
        "    'AutoContrast': autocontrast,\n",
        "    'Equalize': equalize,\n",
        "    'Invert': invert,\n",
        "    'Rotate': rotate,\n",
        "    'Posterize': posterize,\n",
        "    'Solarize': solarize,\n",
        "    'SolarizeAdd': solarize_add,\n",
        "    'Color': color,\n",
        "    'Contrast': contrast,\n",
        "    'Brightness': brightness,\n",
        "    'Sharpness': sharpness,\n",
        "    'ShearX': shear_x,\n",
        "    'ShearY': shear_y,\n",
        "    'TranslateX': translate_x,\n",
        "    'TranslateY': translate_y,\n",
        "    'Cutout': cutout,\n",
        "}\n",
        "\n",
        "def _randomly_negate_tensor(tensor):\n",
        "  \"\"\"With 50% prob turn the tensor negative.\"\"\"\n",
        "  should_flip = tf.cast(tf.floor(tf.random.uniform([]) + 0.5), tf.bool)\n",
        "  final_tensor = tf.cond(should_flip, lambda: tensor, lambda: -tensor)\n",
        "  return final_tensor\n",
        "\n",
        "def _translate_level_to_arg(level, translate_const):\n",
        "  level = (level/_MAX_LEVEL) * float(translate_const)\n",
        "  # Flip level to negative with 50% chance.\n",
        "  level = _randomly_negate_tensor(level)\n",
        "  return (level,)\n",
        "\n",
        "def _rotate_level_to_arg(level):\n",
        "  level = (level/_MAX_LEVEL) * 30.\n",
        "  level = _randomly_negate_tensor(level)\n",
        "  return (level,)\n",
        "\n",
        "def _enhance_level_to_arg(level):\n",
        "  return ((level/_MAX_LEVEL) * 1.8 + 0.1,)\n",
        "\n",
        "def _shear_level_to_arg(level):\n",
        "  level = (level/_MAX_LEVEL) * 0.3\n",
        "  # Flip level to negative with 50% chance.\n",
        "  level = _randomly_negate_tensor(level)\n",
        "  return (level,)\n",
        "\n",
        "def level_to_arg(hparams):\n",
        "  return {\n",
        "      'AutoContrast': lambda level: (),\n",
        "      'Equalize': lambda level: (),\n",
        "      'Invert': lambda level: (),\n",
        "      'Rotate': _rotate_level_to_arg,\n",
        "      'Posterize': lambda level: (int((level/_MAX_LEVEL) * 4),),\n",
        "      'Solarize': lambda level: (int((level/_MAX_LEVEL) * 256),),\n",
        "      'SolarizeAdd': lambda level: (int((level/_MAX_LEVEL) * 110),),\n",
        "      'Color': _enhance_level_to_arg,\n",
        "      'Contrast': _enhance_level_to_arg,\n",
        "      'Brightness': _enhance_level_to_arg,\n",
        "      'Sharpness': _enhance_level_to_arg,\n",
        "      'ShearX': _shear_level_to_arg,\n",
        "      'ShearY': _shear_level_to_arg,\n",
        "      'Cutout': lambda level: (int((level/_MAX_LEVEL) * hparams['cutout_const'],),),\n",
        "      'TranslateX': lambda level: _translate_level_to_arg(\n",
        "          level, hparams['translate_const']),\n",
        "      'TranslateY': lambda level: _translate_level_to_arg(\n",
        "          level, hparams['translate_const']),\n",
        "  }\n",
        "\n",
        "\n",
        "def _parse_policy_info(name, prob, level, replace_value, augmentation_hparams):\n",
        "  \"\"\"Return the function that corresponds to `name` and update `level` param.\"\"\"\n",
        "  func = NAME_TO_FUNC[name]\n",
        "  args = level_to_arg(augmentation_hparams)[name](level)\n",
        "\n",
        "  # Check to see if prob is passed into function. This is used for operations\n",
        "  # where we alter bboxes independently.\n",
        "  if 'prob' in inspect.getfullargspec(func)[0]:\n",
        "    args = tuple([prob] + list(args))\n",
        "\n",
        "  # Add in replace arg if it is required for the function that is being called.\n",
        "  # pytype:disable=wrong-arg-types\n",
        "  if 'replace' in inspect.getfullargspec(func)[0]:\n",
        "    # Make sure replace is the final argument\n",
        "    assert 'replace' == inspect.getfullargspec(func)[0][-1]\n",
        "    args = tuple(list(args) + [replace_value])\n",
        "  return (func, prob, args)\n",
        "\n",
        "\n",
        "def distort_image_with_randaugment(image, num_layers, magnitude):\n",
        "  \"\"\"Applies the RandAugment policy to `image`.\n",
        "  RandAugment is from the paper https://arxiv.org/abs/1909.13719,\n",
        "  Args:\n",
        "    image: `Tensor` of shape [height, width, 3] representing an image.\n",
        "    num_layers: Integer, the number of augmentation transformations to apply\n",
        "      sequentially to an image. Represented as (N) in the paper. Usually best\n",
        "      values will be in the range [1, 3].\n",
        "    magnitude: Integer, shared magnitude across all augmentation operations.\n",
        "      Represented as (M) in the paper. Usually best values are in the range\n",
        "      [5, 30].\n",
        "  Returns:\n",
        "    The augmented version of `image`.\n",
        "  \"\"\"\n",
        "  replace_value = [128] * 3\n",
        "\n",
        "  augmentation_hparams = dict()\n",
        "  augmentation_hparams['cutout_const'] = 40\n",
        "  augmentation_hparams['translate_const'] = 100\n",
        "  \n",
        "  available_ops = [\n",
        "      'AutoContrast', 'Equalize', 'Invert', 'Rotate', 'Posterize',\n",
        "      'Solarize', 'Color', 'Contrast', 'Brightness', 'Sharpness',\n",
        "      'ShearX', 'ShearY', 'TranslateX', 'TranslateY', 'Cutout', 'SolarizeAdd']\n",
        "\n",
        "  for layer_num in range(num_layers):\n",
        "    op_to_select = tf.random.uniform(\n",
        "        [], maxval=len(available_ops), dtype=tf.int32)\n",
        "    random_magnitude = float(magnitude)\n",
        "    with tf.name_scope('randaug_layer_{}'.format(layer_num)):\n",
        "      for (i, op_name) in enumerate(available_ops):\n",
        "        prob = tf.random.uniform([], minval=0.2, maxval=0.8, dtype=tf.float32)\n",
        "        func, _, args = _parse_policy_info(op_name, prob, random_magnitude,\n",
        "                                           replace_value, augmentation_hparams)\n",
        "        image = tf.cond(\n",
        "            tf.equal(i, op_to_select),\n",
        "            lambda selected_func=func, selected_args=args: selected_func(\n",
        "                image, *selected_args),\n",
        "            lambda: image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixe_J4XHHqT7"
      },
      "source": [
        "### Preprocessing functions for JPEG: Image Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk6A5NqnHtqh"
      },
      "source": [
        "CROP_PADDING = RESIZE_SIZE - INPUT_SIZE\n",
        "\n",
        "def distorted_bounding_box_crop(image_bytes,\n",
        "                                bbox,\n",
        "                                min_object_covered=0.1,\n",
        "                                aspect_ratio_range=(0.75, 1.33),\n",
        "                                area_range=(0.05, 1.0),\n",
        "                                max_attempts=100,\n",
        "                                scope=None):\n",
        "  \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n",
        "  See `tf.image.sample_distorted_bounding_box` for more documentation.\n",
        "  Args:\n",
        "    image_bytes: `Tensor` of binary image data.\n",
        "    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\n",
        "        where each coordinate is [0, 1) and the coordinates are arranged\n",
        "        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\n",
        "        image.\n",
        "    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n",
        "        area of the image must contain at least this fraction of any bounding\n",
        "        box supplied.\n",
        "    aspect_ratio_range: An optional list of `float`s. The cropped area of the\n",
        "        image must have an aspect ratio = width / height within this range.\n",
        "    area_range: An optional list of `float`s. The cropped area of the image\n",
        "        must contain a fraction of the supplied image within in this range.\n",
        "    max_attempts: An optional `int`. Number of attempts at generating a cropped\n",
        "        region of the image of the specified constraints. After `max_attempts`\n",
        "        failures, return the entire image.\n",
        "    scope: Optional `str` for name scope.\n",
        "  Returns:\n",
        "    cropped image `Tensor`\n",
        "  \"\"\"\n",
        "  with tf.name_scope('distorted_bounding_box_crop'):\n",
        "    shape = tf.image.extract_jpeg_shape(image_bytes)\n",
        "    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n",
        "        shape,\n",
        "        bounding_boxes=bbox,\n",
        "        min_object_covered=min_object_covered,\n",
        "        aspect_ratio_range=aspect_ratio_range,\n",
        "        area_range=area_range,\n",
        "        max_attempts=max_attempts,\n",
        "        use_image_if_no_bounding_boxes=True)\n",
        "    bbox_begin, bbox_size, _ = sample_distorted_bounding_box\n",
        "\n",
        "    # Crop the image to the specified bounding box.\n",
        "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\n",
        "    target_height, target_width, _ = tf.unstack(bbox_size)\n",
        "    crop_window = tf.stack([offset_y, offset_x, target_height, target_width])\n",
        "    image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n",
        "\n",
        "    return image\n",
        "\n",
        "def _at_least_x_are_equal(a, b, x):\n",
        "  \"\"\"At least `x` of `a` and `b` `Tensors` are equal.\"\"\"\n",
        "  match = tf.equal(a, b)\n",
        "  match = tf.cast(match, tf.int32)\n",
        "  return tf.greater_equal(tf.reduce_sum(match), x)\n",
        "\n",
        "\n",
        "def _resize_image(image, image_size, method=None):\n",
        "  if method is None:\n",
        "    return tf.image.resize(image, [image_size, image_size], 'bicubic')\n",
        "  return tf.image.resize(image, [image_size, image_size], method)\n",
        "\n",
        "\n",
        "def _decode_and_center_crop(image_bytes, image_size, resize_method=None):\n",
        "  \"\"\"Crops to center of image with padding then scales image_size.\"\"\"\n",
        "  shape = tf.image.extract_jpeg_shape(image_bytes)\n",
        "  image_height = shape[0]\n",
        "  image_width = shape[1]\n",
        "\n",
        "  padded_center_crop_size = tf.cast(\n",
        "      ((image_size / (image_size + CROP_PADDING)) *\n",
        "       tf.cast(tf.minimum(image_height, image_width), tf.float32)),\n",
        "      tf.int32)\n",
        "\n",
        "  offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n",
        "  offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n",
        "  crop_window = tf.stack([offset_height, offset_width,\n",
        "                          padded_center_crop_size, padded_center_crop_size])\n",
        "  image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n",
        "  image = _resize_image(image, image_size, resize_method)\n",
        "  return image\n",
        "\n",
        "\n",
        "def _decode_and_random_crop(image_bytes, image_size, resize_method=None):\n",
        "  \"\"\"Make a random crop of image_size.\"\"\"\n",
        "  bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n",
        "  image = distorted_bounding_box_crop(\n",
        "      image_bytes,\n",
        "      bbox,\n",
        "      min_object_covered=0.1,\n",
        "      aspect_ratio_range=(3. / 4, 4. / 3.),\n",
        "      area_range=(0.08, 1.0),\n",
        "      max_attempts=10,\n",
        "      scope=None)\n",
        "  original_shape = tf.io.extract_jpeg_shape(image_bytes)\n",
        "  bad = _at_least_x_are_equal(original_shape, tf.shape(image), 3)\n",
        "\n",
        "  image = tf.cond(\n",
        "      bad,\n",
        "      lambda: _decode_and_center_crop(image_bytes, image_size),\n",
        "      lambda: _resize_image(image, image_size, resize_method))\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def _flip(image):\n",
        "  \"\"\"Random horizontal image flip.\"\"\"\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8RtmEpg1Jhg"
      },
      "source": [
        "### Preprocessing function for JPEG: Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeepz4Zu1Ri6"
      },
      "source": [
        "def preprocess_for_train(image_bytes,\n",
        "                         use_bfloat16=USE_BFLOAT16,\n",
        "                         image_size=INPUT_SIZE,\n",
        "                         randaug_num_layers=None,\n",
        "                         randaug_magnitude=None,\n",
        "                         resize_method=None):\n",
        "  image = _decode_and_random_crop(image_bytes, image_size, resize_method)\n",
        "  image = _flip(image)\n",
        "  image = tf.reshape(image, [image_size, image_size, 3])\n",
        "\n",
        "  input_image_type = image.dtype\n",
        "  image = tf.clip_by_value(image, 0.0, 255.0)\n",
        "  image = tf.cast(image, dtype=tf.uint8)\n",
        "  image = distort_image_with_randaugment(image, randaug_num_layers,\n",
        "                                         randaug_magnitude)\n",
        "  image = tf.cast(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_for_eval(image_bytes,\n",
        "                        use_bfloat16=USE_BFLOAT16,\n",
        "                        image_size=INPUT_SIZE,\n",
        "                        resize_method=None):\n",
        "  image = _decode_and_center_crop(image_bytes, image_size, resize_method)\n",
        "  image = tf.reshape(image, [image_size, image_size, 3])\n",
        "  image = tf.cast(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_image(image_bytes,\n",
        "                     is_training=False,\n",
        "                     use_bfloat16=USE_BFLOAT16,\n",
        "                     image_size=INPUT_SIZE,\n",
        "                     randaug_num_layers=None,\n",
        "                     randaug_magnitude=None,\n",
        "                     resize_method=None):\n",
        "  \"\"\"Preprocesses the given image.\n",
        "  Args:\n",
        "    image_bytes: `Tensor` representing an image binary of arbitrary size.\n",
        "    is_training: `bool` for whether the preprocessing is for training.\n",
        "    use_bfloat16: `bool` for whether to use bfloat16.\n",
        "    image_size: image size.\n",
        "    randaug_num_layers: 'int', if RandAug is used, what should the number of\n",
        "      layers be. See autoaugment.py for detailed description.\n",
        "    randaug_magnitude: 'int', if RandAug is used, what should the magnitude\n",
        "      be. See autoaugment.py for detailed description.\n",
        "    resize_method: 'string' or None. Use resize_bicubic in default.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor` with value range of [0, 255].\n",
        "  \"\"\"\n",
        "  if is_training:\n",
        "    return preprocess_for_train(\n",
        "        image_bytes, use_bfloat16, image_size,\n",
        "        randaug_num_layers, randaug_magnitude, resize_method)\n",
        "  else:\n",
        "    return preprocess_for_eval(image_bytes, use_bfloat16, image_size,\n",
        "                               resize_method)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgP8YfOLYGm3"
      },
      "source": [
        "### Normal Augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldqt3dxiYTkC"
      },
      "source": [
        "def preprocess_normal(x, is_train, use_bfloat16, image_size):\n",
        "  def normal_augmentation(x):\n",
        "    x = tf.image.random_flip_left_right(x, seed=SEED)\n",
        "    x = tf.image.random_flip_up_down(x, seed=SEED)\n",
        "    x = tf.image.random_brightness(x, 0.4, seed=SEED)\n",
        "    x = tf.image.random_contrast(x, 0.6, 1.4, seed=SEED)\n",
        "    x = tf.image.random_saturation(x, 0.6, 1.4, seed=SEED)\n",
        "    return x\n",
        "\n",
        "  dtype = 'bfloat16' if use_bfloat16 else 'float32'\n",
        "  shape = tf.shape(x)\n",
        "  h = shape[0]\n",
        "  w = shape[1]\n",
        "  resized_size = int(image_size * (1/0.875))\n",
        "  target = [(h//w)*resized_size, resized_size] if h > w else [resized_size, (w//h)*resized_size]\n",
        "\n",
        "  x = tf.image.resize(x, target, antialias=True)\n",
        "  x = tf.image.random_crop(x, [image_size, image_size, 3]) if is_train else tf.image.resize_with_crop_or_pad(x, image_size, image_size)\n",
        "  x = normal_augmentation(x) if is_train else x\n",
        "  x = tf.cast(x, dtype)\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOEKq15SHjIG"
      },
      "source": [
        "### Loader function using TFDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Xm5eqd1ltC"
      },
      "source": [
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "def labels_to_multihot(labels):\n",
        "  return tf.minimum(tf.reduce_sum(tf.one_hot(labels, depth=7), axis=0), 1.0)\n",
        "\n",
        "def apply_as_supervised(combined_data):\n",
        "  image = combined_data['image']\n",
        "  labels = combined_data['objects']['label']\n",
        "  multi_hot = labels_to_multihot(labels)\n",
        "  return image, multi_hot\n",
        "\n",
        "def decode_multihot(multihot):\n",
        "  if isinstance(multihot, tf.Tensor):\n",
        "    multihot = multihot.numpy()\n",
        "  labels = np.where(multihot != 0.0)[0]\n",
        "  text_labels = [OBJECT_LABELS[label] for label in labels]\n",
        "  return ' '.join(text_labels)\n",
        "\n",
        "def load_data(data_dir,\n",
        "              split,\n",
        "              is_fix=False,\n",
        "              crop_ratio=None,\n",
        "              is_normalize=True,\n",
        "              strategy=None):\n",
        "  \n",
        "  global CROP_PADDING\n",
        "  is_train = True if split == 'train' else False\n",
        "\n",
        "  if is_fix:\n",
        "    input_size = FIX_INPUT_SIZE\n",
        "    CROP_PADDING = FIX_RESIZE_SIZE - FIX_INPUT_SIZE\n",
        "  else:\n",
        "    input_size = INPUT_SIZE\n",
        "    CROP_PADDING = RESIZE_SIZE - INPUT_SIZE\n",
        "\n",
        "  if RAND_AUGMENT:\n",
        "    preprocess = lambda x, y: (preprocess_image(x, is_training=is_train,\n",
        "                                                use_bfloat16=USE_BFLOAT16,\n",
        "                                                image_size=input_size,\n",
        "                                                randaug_num_layers=RA_NUM_LAYERS,\n",
        "                                                randaug_magnitude=RA_MAGNITUDE), y)\n",
        "  else:\n",
        "    preprocess = lambda x, y: (preprocess_normal(x, is_train=is_train,\n",
        "                                                 use_bfloat16=USE_BFLOAT16,\n",
        "                                                 image_size=input_size), y)\n",
        "    \n",
        "  normalize = lambda x, y: (preprocess_input(x, mode='torch'), y)\n",
        "  central_crop = lambda x, y : (tf.image.central_crop(x, crop_ratio), y)\n",
        "\n",
        "  data = (tfds.load(NAME_DATASET, data_dir=data_dir,\n",
        "                    decoders={'image': tfds.decode.SkipDecoding()},\n",
        "                    split=split) if RAND_AUGMENT else\n",
        "          tfds.load(NAME_DATASET, data_dir=data_dir, split=split))\n",
        "  data = data.shuffle(10000) if is_train else data\n",
        "  data = data.map(apply_as_supervised, -1)\n",
        "  data = data.map(preprocess, -1)\n",
        "  data = data.batch(BATCH_SIZE, drop_remainder=True) if is_train else data.batch(BATCH_SIZE)\n",
        "  data = data.map(normalize, -1) if is_normalize else data\n",
        "  data = data.map(central_crop, -1) if crop_ratio else data\n",
        "  data = data.prefetch(-1)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHC7Ef_8e3Q"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YknK0pOO8i3k"
      },
      "source": [
        "def show_image(value, name=None):\n",
        "  if value.dtype == tf.bfloat16:\n",
        "    value = tf.cast(value, 'float32')\n",
        "    if tf.reduce_max(value) > 2:\n",
        "      value /= 255.\n",
        "\n",
        "  if isinstance(value, tf.Tensor):\n",
        "    value = value.numpy()\n",
        "  \n",
        "  if len(value.shape) == 4:\n",
        "    value = value[0]\n",
        "\n",
        "  plt.figure(figsize=(13,13))\n",
        "  plt.title(name)\n",
        "  plt.imshow(value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kudlYMmrWwQ"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKg_mPY5rYcf"
      },
      "source": [
        "def write_hist_weight(writer, model, epoch):\n",
        "  with writer.as_default():\n",
        "    for weight in model.weights:\n",
        "      tf.summary.histogram(weight.name, weight, step=epoch)\n",
        "  \n",
        "def write_scalar(writer, value, epoch, name):\n",
        "  with writer.as_default():\n",
        "    tf.summary.scalar(name, value, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDBX0dy7Vdci"
      },
      "source": [
        "# **Main**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91gBE3c8UPLO"
      },
      "source": [
        "## Create file writers for tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr5F3XGcUS1d"
      },
      "source": [
        "# Create a file writer for tensorboard.\n",
        "if WRITE_TB:\n",
        "  train_writer = tf.summary.create_file_writer(\n",
        "    os.path.join(BUCKET, 'ai', 'tensorboard', TOKEN, 'train')\n",
        "  )\n",
        "  valid_writer = tf.summary.create_file_writer(\n",
        "    os.path.join(BUCKET, 'ai', 'tensorboard', TOKEN, 'validation')\n",
        "  )\n",
        "  test_writer = tf.summary.create_file_writer(\n",
        "      os.path.join(BUCKET, 'ai', 'tensorboard', TOKEN, 'test')\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbQxj4wvVpV9"
      },
      "source": [
        "## Load a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8y5hNT9LDBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50367bd1-e684-4926-c2e4-f8f61238b1e3"
      },
      "source": [
        "train_data = load_data(DATA_DIR,\n",
        "                       split='train',\n",
        "                       strategy=strategy)\n",
        "valid_data = load_data(DATA_DIR,\n",
        "                       split='validation',\n",
        "                       strategy=strategy)\n",
        "test_data = load_data(DATA_DIR,\n",
        "                      split='test',\n",
        "                      strategy=strategy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygmX0FhnxOC"
      },
      "source": [
        "## Build a model and define functions for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16w2BwEXPdUL"
      },
      "source": [
        "### Functions for Distributed Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON68l8FCPjRF"
      },
      "source": [
        "def _distribute_tensors(ctx, tensor):\n",
        "  idx = ctx.replica_id_in_sync_group\n",
        "  batch_size = tensor.shape[0]\n",
        "  k = int(math.ceil(batch_size / 8.0))\n",
        "  return tensor[idx*k:(idx+1)*k]\n",
        "\n",
        "def make_tensors_per_replica(tensors, strategy):\n",
        "  func = strategy.experimental_distribute_values_from_function\n",
        "  return func(lambda ctx: _distribute_tensors(ctx, tensors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CqSHnJ0U1ed"
      },
      "source": [
        "### Loss functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMxQQCyKU09R"
      },
      "source": [
        "def f1_loss_with_logits(labels, predictions, from_logits=False):\n",
        "  if from_logits:\n",
        "    predictions = tf.nn.sigmoid(predictions)\n",
        "  epsilon = 1e-7\n",
        "\n",
        "  tp = tf.reduce_sum(labels*predictions, axis=-1)\n",
        "  tn = tf.reduce_sum((1-labels)*(1-predictions), axis=-1)\n",
        "  fp = tf.reduce_sum((1-labels)*predictions, axis=-1)\n",
        "  fn = tf.reduce_sum(labels*(1-predictions), axis=-1)\n",
        "  precision = tp / (tp + fp + epsilon)\n",
        "  recall = tp / (tp + fn + epsilon)\n",
        "\n",
        "  f1 = 2*precision*recall / (precision + recall + epsilon)\n",
        "  # f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "  return 1 - f1\n",
        "\n",
        "def hybrid_loss(labels, predictions, from_logits=False):\n",
        "  loss1 = f1_loss_with_logits(labels, predictions, from_logits=from_logits)\n",
        "  loss2 = tf.keras.losses.binary_crossentropy(labels, predictions, from_logits=from_logits,\n",
        "                                              label_smoothing=LABEL_SMOOTHING)\n",
        "  return loss1*2.0 + loss2\n",
        "\n",
        "_loss_functions = {\n",
        "    'f1_loss': functools.partial(f1_loss_with_logits, from_logits=True),\n",
        "    'categorical_crossentropy': tf.keras.losses.CategoricalCrossentropy(True, LABEL_SMOOTHING, tf.keras.losses.Reduction.NONE),\n",
        "    'binary_crossentropy': tf.keras.losses.BinaryCrossentropy(True, LABEL_SMOOTHING, tf.keras.losses.Reduction.NONE),\n",
        "    'hybrid': functools.partial(hybrid_loss, from_logits=True)\n",
        "}\n",
        "\n",
        "with strategy.scope():\n",
        "  loss_function = _loss_functions[LOSS_FUNC]\n",
        "\n",
        "  def compute_loss(labels, predictions):\n",
        "    per_example_loss = loss_function(labels, predictions)\n",
        "    return tf.nn.compute_average_loss(per_example_loss,\n",
        "                                      global_batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opyctmT7VDHX"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "910GpagrVFA3"
      },
      "source": [
        "with strategy.scope():\n",
        "  train_accuracy = tfa.metrics.F1Score(7, average='macro', threshold=0.5, name='train_f1_score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H81HTrIvVNjf"
      },
      "source": [
        "### Model and Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjITbBsQrS0v"
      },
      "source": [
        "#### Define a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfHiB_6HrSI5"
      },
      "source": [
        "def MyModel(name):\n",
        "  efficientnet_builder = getattr(efn, f'EfficientNet{MODEL_CODE}')\n",
        "  pretrained_model = efficientnet_builder(weights='noisy-student', include_top=False)\n",
        "  num_layers = len(pretrained_model.layers)\n",
        "  num_trainable_layers = int(num_layers * OPEN_RATIO)\n",
        "  for layer in pretrained_model.layers:\n",
        "      layer.trainable = False\n",
        "  for layer in pretrained_model.layers[-num_trainable_layers:]:\n",
        "    layer.trainable = True\n",
        "  \n",
        "  avg_pool = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')\n",
        "  top_dropout = tf.keras.layers.Dropout(0.5, name='top_dropout')\n",
        "  logits = tf.keras.layers.Dense(7, activation='linear', dtype='float32', name='logits')\n",
        "\n",
        "  # Connect layers.\n",
        "  inputs = tf.keras.Input(shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
        "  x = pretrained_model(inputs)\n",
        "  x = avg_pool(x)\n",
        "  x = top_dropout(x)\n",
        "  outputs = logits(x)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEKkJs2LeFLq"
      },
      "source": [
        "#### Learning Rate Schedule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-g7AGqlKFi6"
      },
      "source": [
        "def exponential_decay(initial_lr, global_step, decay_steps, decay_factor):\n",
        "  p = tf.cast(global_step, 'float32') / tf.cast(decay_steps, 'float32')\n",
        "  p = tf.floor(p)\n",
        "  lr = tf.multiply(initial_lr, tf.pow(decay_factor, p))\n",
        "  return lr\n",
        "\n",
        "def cosine_decay(initial_lr, global_step, total_steps):\n",
        "  lr = 0.5 * initial_lr * (1.0 + tf.cos(math.pi * tf.cast(global_step, 'float32') / total_steps))\n",
        "  return lr\n",
        "\n",
        "def poly_decay(initial_lr, global_step, decay_steps, warmup_steps, end_lr=0.1, power=2.0):\n",
        "  p = tf.divide(tf.cast(global_step, 'float32'), decay_steps)\n",
        "  lr = tf.add(tf.multiply(initial_lr - end_lr, tf.pow(1 - p, power)), end_lr)\n",
        "  return lr\n",
        "\n",
        "class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(\n",
        "      self,\n",
        "      initial_lr,\n",
        "      steps_per_epoch,\n",
        "      total_steps=None,\n",
        "      lr_decay_type='exponential',\n",
        "      decay_factor=0.97,\n",
        "      decay_epochs=2.4,\n",
        "      warmup_epochs=5):\n",
        "    super(LRSchedule, self).__init__()\n",
        "    self.initial_lr = initial_lr\n",
        "    self.total_steps = total_steps\n",
        "    self.lr_decay_type = lr_decay_type\n",
        "    self.decay_factor = decay_factor\n",
        "    self.decay_steps = decay_epochs * steps_per_epoch\n",
        "    self.warmup_steps = warmup_epochs * steps_per_epoch\n",
        "    self.prev_lr = tf.cast(initial_lr, 'float32')\n",
        "\n",
        "  def __call__(self, global_step):\n",
        "    with tf.name_scope(self.lr_decay_type.capitalize() + 'Decay') as name:\n",
        "      initial_lr = tf.cast(self.initial_lr, 'float32')\n",
        "      if self.lr_decay_type == 'exponential':\n",
        "        lr = exponential_decay(initial_lr, global_step, self.decay_steps, self.decay_factor)\n",
        "      elif self.lr_decay_type == 'cosine':\n",
        "        lr = cosine_decay(initial_lr, global_step, self.total_steps)\n",
        "      elif self.lr_decay_type == 'constant':\n",
        "        lr = initial_lr\n",
        "      elif self.lr_decay_type == 'poly':\n",
        "        min_step = tf.constant(1, dtype='int64')\n",
        "        decay_steps = tf.maximum(min_step, tf.subtract(global_step, self.warmup_steps))\n",
        "        lr = poly_decay(initial_lr, global_step, decay_steps, self.warmup_steps)\n",
        "      else:\n",
        "        assert False, f'Unknown lr_decay_type: {self.lr_decay_type}'\n",
        "\n",
        "      if self.warmup_steps:\n",
        "        warmup_lr = initial_lr * tf.cast(global_step, 'float32') / tf.cast(self.warmup_steps, 'float32')\n",
        "        lr = tf.cond(global_step < self.warmup_steps, lambda: warmup_lr, lambda: lr)\n",
        "      return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtXn0WWZeKsG"
      },
      "source": [
        "#### Build a model in scope of strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3se7JBzZVPJ0",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24913013-3110-461b-fd7c-b54cc7ecbf5e"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = MyModel(name=f'EfficientNet{MODEL_CODE}')\n",
        "  lr_schedule = LRSchedule(INITIAL_LR, len(train_data), EPOCHS*len(train_data),\n",
        "                           LR_DECAY_TYPE, decay_epochs=LR_DECAY_EPOCHS,\n",
        "                           warmup_epochs=LR_WARMUP_EPOCHS)\n",
        "  if OPTIMIZER == 'SGD':\n",
        "    optimizer = tf.keras.optimizers.SGD(lr_schedule, momentum=0.9, nesterov=True)\n",
        "  elif OPTIMIZER == 'RMSprop':\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr_schedule, rho=0.9, momentum=0.9, centered=True)\n",
        "  elif OPTIMIZER == 'Adam':\n",
        "    optimizer = tf.keras.optimizers.Adam(lr_schedule)\n",
        "  else:\n",
        "    assert False, f'Unimplemented optimizer: {OPTIMIZER}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b7_noisy-student_notop.h5\n",
            "258072576/258068648 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy1PndkpUmFz"
      },
      "source": [
        "### Step functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpOS3iWxS4Ys"
      },
      "source": [
        "def train_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = compute_loss(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_accuracy.update_state(labels, tf.nn.sigmoid(predictions))\n",
        "  return loss\n",
        "\n",
        "\n",
        "def test_step(images):\n",
        "  predictions = model(images, training=False)\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iczsxC5_V4gI"
      },
      "source": [
        "@tf.function\n",
        "def distributed_train_step(inputs_per):\n",
        "  per_replica_losses = strategy.run(train_step, args=(inputs_per,))\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "                         axis=None)\n",
        "\n",
        "@tf.function\n",
        "def distributed_test_step(images_per):\n",
        "  return strategy.run(test_step, args=(images_per,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtNjIpq2SXdL"
      },
      "source": [
        "### Train function & Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWA79GTDEgYC"
      },
      "source": [
        "BEST_TEST_SCORE = 0\n",
        "BEST_TEST_CLASSWISE_SCORE = 0\n",
        "\n",
        "def train(train_data,\n",
        "          valid_data,\n",
        "          test_data,\n",
        "          epochs,\n",
        "          strategy=strategy,\n",
        "          store_ckpt=False,\n",
        "          verbose=0):\n",
        "  global EPOCH\n",
        "  global BEST_TEST_SCORE\n",
        "  global BEST_TEST_CLASSWISE_SCORE\n",
        "  \n",
        "  def train_epoch(train_data):\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for x, y in train_data:\n",
        "      num_batches += 1\n",
        "      x_per = make_tensors_per_replica(x, strategy)\n",
        "      y_per = make_tensors_per_replica(y, strategy)\n",
        "      total_loss += distributed_train_step((x_per, y_per))\n",
        "      train_loss = total_loss / num_batches\n",
        "      if verbose:\n",
        "        train_data.set_description(f'Epoch {EPOCH:3}/{epochs:3}')\n",
        "        train_data.set_postfix(\n",
        "            loss=train_loss.numpy(),\n",
        "            f1_score=train_accuracy.result().numpy(),\n",
        "        )\n",
        "    CURRENT_LR = optimizer._decayed_lr('float32').numpy()\n",
        "    return train_loss\n",
        "\n",
        "  while EPOCH <= epochs:\n",
        "    if WRITE_TB:\n",
        "      write_scalar(train_writer, optimizer._decayed_lr('float32'), EPOCH-1, 'learning rate')\n",
        "\n",
        "    # Train\n",
        "    begin_time = time.perf_counter()\n",
        "    if verbose:\n",
        "      with tqdm(train_data, total=len(train_data), file=sys.stdout) as tqdm_train_data:\n",
        "        train_loss = train_epoch(tqdm_train_data)\n",
        "    else:\n",
        "      print(f'Epoch {EPOCH:3}/{epochs:3}', end='')\n",
        "      train_loss = train_epoch(train_data)\n",
        "\n",
        "    # Validation ===============================================================\n",
        "    # Explore given thresholds to find a best f1-score and threshold.\n",
        "    nums = 200\n",
        "    thresholds = np.arange(1, 1+nums) / nums * 0.5\n",
        "\n",
        "    y_trues, y_logits = get_prediction(valid_data)\n",
        "    y_probs = tf.nn.sigmoid(y_logits)\n",
        "    y_trues = y_trues.numpy()\n",
        "    y_probs = y_probs.numpy()\n",
        "\n",
        "    valid_threshold = 0\n",
        "    valid_score = 0\n",
        "    for threshold in thresholds:\n",
        "      y_preds = np.where(y_probs >= threshold, 1.0, 0.0)\n",
        "      score = 0\n",
        "      for i in range(7):\n",
        "        score += f1_score(y_trues[:,i], y_preds[:,i])\n",
        "      score /= 7.\n",
        "      if valid_score < score:\n",
        "        valid_threshold = threshold\n",
        "        valid_score = score\n",
        "\n",
        "    ## classwise\n",
        "    valid_classwise_thresholds = []\n",
        "    valid_classwise_scores = []\n",
        "    for i in range(7):\n",
        "      y_prob = y_probs[:, i]\n",
        "      y_true = y_trues[:, i]\n",
        "\n",
        "      best_classwise_threshold = 0\n",
        "      best_classwise_score = 0\n",
        "      for threshold in thresholds:\n",
        "        y_pred = np.where(y_prob >= threshold, 1.0, 0.0)\n",
        "        classwise_score = f1_score(y_true, y_pred)\n",
        "        if best_classwise_score < classwise_score:\n",
        "          best_classwise_threshold = threshold\n",
        "          best_classwise_score = classwise_score\n",
        "      valid_classwise_thresholds.append(best_classwise_threshold)\n",
        "      valid_classwise_scores.append(best_classwise_score)\n",
        "    valid_classwise_score = np.mean(valid_classwise_scores)\n",
        "    # ==========================================================================\n",
        "    \n",
        "\n",
        "    # Test =====================================================================\n",
        "    \n",
        "    y_trues, y_logits = get_prediction(test_data)\n",
        "    y_probs = tf.nn.sigmoid(y_logits)\n",
        "    y_trues = y_trues.numpy()\n",
        "    y_probs = y_probs.numpy()\n",
        "    y_preds = np.where(y_probs >= valid_threshold, 1.0, 0.0)\n",
        "    test_score = 0\n",
        "    for i in range(7):\n",
        "      test_score += f1_score(y_trues[:, i], y_preds[:, i])\n",
        "    test_score /= 7.\n",
        "\n",
        "    ## classwise\n",
        "    test_classwise_scores = []\n",
        "    for i in range(7):\n",
        "      y_prob = y_probs[:, i]\n",
        "      y_true = y_trues[:, i]\n",
        "      y_pred = np.where(y_prob >= valid_classwise_thresholds[i], 1.0, 0.0)\n",
        "      test_classwise_scores.append(f1_score(y_true, y_pred))\n",
        "    test_classwise_score = np.mean(test_classwise_scores)\n",
        "\n",
        "    # 0: no save\n",
        "    # 1: saved for universal\n",
        "    # 2: saved for classwise\n",
        "    # 3: saved for both\n",
        "    save_flag = 0\n",
        "    ckpt_paths = []\n",
        "    if BEST_TEST_SCORE < test_score and store_ckpt:\n",
        "      BEST_TEST_SCORE = test_score\n",
        "      save_flag += 1\n",
        "      ckpt_paths.append(os.path.join(CKPT_PATH, 'universal'))\n",
        "    if BEST_TEST_CLASSWISE_SCORE < test_classwise_score and store_ckpt:\n",
        "      BEST_TEST_CLASSWISE_SCORE = test_classwise_score\n",
        "      save_flag += 2\n",
        "      ckpt_paths.append(os.path.join(CKPT_PATH, 'classwise'))\n",
        "\n",
        "    # Save =====================================================================\n",
        "    if save_flag:\n",
        "      threshold = {\n",
        "          'universal': valid_threshold,\n",
        "          'classwise': valid_classwise_thresholds,\n",
        "      }\n",
        "\n",
        "      # Save the model architecture.\n",
        "      if EPOCH == 1:\n",
        "        model_path = os.path.join(CKPT_PATH, 'model.json')\n",
        "        with tf.io.gfile.GFile(model_path, 'w') as f:\n",
        "          json.dump(model.to_json(), f)\n",
        "\n",
        "      # Save parameters of the model.\n",
        "      for ckpt_path in ckpt_paths:\n",
        "        model.save_weights(ckpt_path, overwrite=True, save_format='tf')\n",
        "        # Save the threhold values.\n",
        "        with tf.io.gfile.GFile(f'{ckpt_path}.threshold', 'wb') as f:\n",
        "          pickle.dump(threshold, f)\n",
        "    \n",
        "    # ==========================================================================\n",
        "\n",
        "\n",
        "    # Tensorboard\n",
        "    if WRITE_TB:\n",
        "      with train_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss, step=EPOCH)\n",
        "        tf.summary.scalar('f1_score', train_accuracy.result(), step=EPOCH)\n",
        "      with valid_writer.as_default():\n",
        "        tf.summary.scalar('universal_threshold', valid_threshold, step=EPOCH)\n",
        "        for i in range(7):\n",
        "          tf.summary.scalar(f'{OBJECT_LABELS[i]}_threshold', valid_classwise_thresholds[i], step=EPOCH)\n",
        "          tf.summary.scalar(f'{OBJECT_LABELS[i]}_f1_score', valid_classwise_scores[i], step=EPOCH)\n",
        "        tf.summary.scalar('universal_f1_score', valid_score, step=EPOCH)\n",
        "        tf.summary.scalar('classwise_f1_score', valid_classwise_score, step=EPOCH)\n",
        "      with test_writer.as_default():\n",
        "        tf.summary.scalar('universal_f1_score', test_score, step=EPOCH)\n",
        "        tf.summary.scalar('classwise_f1_score', test_classwise_score, step=EPOCH)\n",
        "        for i in range(7):\n",
        "          tf.summary.scalar(f'{OBJECT_LABELS[i]}_f1_score', test_classwise_scores[i], step=EPOCH)\n",
        "\n",
        "    end_time = time.perf_counter()\n",
        "\n",
        "    print((f' | Elapsed Time {end_time - begin_time:6.2f} secs'\n",
        "           f' | Loss {train_loss.numpy():.4f}'\n",
        "           f'  F1 {train_accuracy.result().numpy():.4f}'\n",
        "           f' | Val th: {valid_threshold:.2f}'\n",
        "           f'  Val F1: {valid_score:.4f}'\n",
        "           f'  Val cw F1: {valid_classwise_score:.4f}'\n",
        "           f' | Test F1: {test_score:.4f}'\n",
        "           f'  Test cw F1: {test_classwise_score:.4f} | '), end='')\n",
        "    if save_flag == 0:\n",
        "      print()\n",
        "    elif save_flag == 1:\n",
        "      print('Saved for an universal f1 score.')\n",
        "    elif save_flag == 2:\n",
        "      print('Saved for a classwise f1 score.')\n",
        "    elif save_flag == 3:\n",
        "      print('Saved for both f1 scores.')\n",
        "    \n",
        "    train_accuracy.reset_states()\n",
        "    EPOCH += 1\n",
        "  return BEST_TEST_SCORE, BEST_TEST_CLASSWISE_SCORE\n",
        "\n",
        "def get_prediction(valid_data):\n",
        "  ta_logits = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
        "  ta_labels = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
        "  for i, (x, y) in enumerate(valid_data):\n",
        "    x_per = make_tensors_per_replica(x, strategy)\n",
        "    ta_logits = ta_logits.write(i, tf.concat(distributed_test_step(x_per,).values, axis=0))\n",
        "    ta_labels = ta_labels.write(i, y)\n",
        "\n",
        "  labels = ta_labels.concat()\n",
        "  logits = ta_logits.concat()\n",
        "\n",
        "  return labels, logits\n",
        "\n",
        "def evaluate(valid_data, threshold=0.5, verbose=1):\n",
        "  y_trues, y_logits = get_prediction(valid_data)\n",
        "  y_probs = tf.nn.sigmoid(y_logits)\n",
        "  y_preds = tf.where(y_probs >= threshold, 1.0, 0.0)\n",
        "  \n",
        "  np_y_preds = y_preds.numpy()\n",
        "  np_y_trues = y_trues.numpy()\n",
        "\n",
        "  score = 0\n",
        "  for i in range(7):\n",
        "    score += f1_score(np_y_trues[:,i], np_y_preds[:,i])\n",
        "  score /= 7.\n",
        "\n",
        "  if verbose:\n",
        "    print(f'F1 Score: {score}')\n",
        "\n",
        "  return score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwCxIeN-SVrF"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6kn1eRNeM9z",
        "cellView": "form"
      },
      "source": [
        "#@markdown # **TensorBoard**\n",
        "if SHOW_TENSORBOARD:\n",
        "  TB_PATH = os.path.join(BUCKET, 'ai', 'tensorboard')\n",
        "  %reload_ext tensorboard\n",
        "  %tensorboard --logdir $TB_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Npg7GBAnZrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d7bf94-75a0-4088-d4b3-ba3153b72d72"
      },
      "source": [
        "train(train_data, valid_data, test_data, epochs=EPOCHS, verbose=0, store_ckpt=STORE_CKPT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch   1/150 | Elapsed Time 286.91 secs | Loss 0.6769  F1 0.3445 | Val th: 0.49  Val F1: 0.3924  Val cw F1: 0.4233 | Test F1: 0.3367  Test cw F1: 0.3779 | Saved for both f1 scores.\n",
            "Epoch   2/150 | Elapsed Time  75.15 secs | Loss 0.6645  F1 0.3862 | Val th: 0.50  Val F1: 0.4443  Val cw F1: 0.4551 | Test F1: 0.3771  Test cw F1: 0.3945 | Saved for both f1 scores.\n",
            "Epoch   3/150 | Elapsed Time  74.45 secs | Loss 0.6347  F1 0.4143 | Val th: 0.50  Val F1: 0.4449  Val cw F1: 0.4921 | Test F1: 0.3904  Test cw F1: 0.4239 | Saved for both f1 scores.\n",
            "Epoch   4/150 | Elapsed Time  76.28 secs | Loss 0.5935  F1 0.3943 | Val th: 0.44  Val F1: 0.4682  Val cw F1: 0.5561 | Test F1: 0.4037  Test cw F1: 0.4266 | Saved for both f1 scores.\n",
            "Epoch   5/150 | Elapsed Time  67.54 secs | Loss 0.5631  F1 0.3414 | Val th: 0.16  Val F1: 0.4804  Val cw F1: 0.5498 | Test F1: 0.4169  Test cw F1: 0.4143 | Saved for an universal f1 score.\n",
            "Epoch   6/150 | Elapsed Time  74.63 secs | Loss 0.5528  F1 0.3116 | Val th: 0.10  Val F1: 0.4850  Val cw F1: 0.5622 | Test F1: 0.4240  Test cw F1: 0.4305 | Saved for both f1 scores.\n",
            "Epoch   7/150 | Elapsed Time  67.68 secs | Loss 0.5507  F1 0.3194 | Val th: 0.05  Val F1: 0.4840  Val cw F1: 0.5673 | Test F1: 0.4100  Test cw F1: 0.4428 | Saved for a classwise f1 score.\n",
            "Epoch   8/150 | Elapsed Time  59.57 secs | Loss 0.5491  F1 0.3308 | Val th: 0.03  Val F1: 0.4694  Val cw F1: 0.5670 | Test F1: 0.4026  Test cw F1: 0.4426 | \n",
            "Epoch   9/150 | Elapsed Time  66.00 secs | Loss 0.5453  F1 0.3555 | Val th: 0.02  Val F1: 0.4687  Val cw F1: 0.5555 | Test F1: 0.4168  Test cw F1: 0.4703 | Saved for a classwise f1 score.\n",
            "Epoch  10/150 | Elapsed Time  66.20 secs | Loss 0.5421  F1 0.3738 | Val th: 0.01  Val F1: 0.4531  Val cw F1: 0.5368 | Test F1: 0.4079  Test cw F1: 0.4885 | Saved for a classwise f1 score.\n",
            "Epoch  11/150 | Elapsed Time  66.65 secs | Loss 0.5377  F1 0.3935 | Val th: 0.07  Val F1: 0.4572  Val cw F1: 0.5256 | Test F1: 0.4075  Test cw F1: 0.4927 | Saved for a classwise f1 score.\n",
            "Epoch  12/150 | Elapsed Time  59.36 secs | Loss 0.5347  F1 0.4092 | Val th: 0.13  Val F1: 0.4746  Val cw F1: 0.5255 | Test F1: 0.4194  Test cw F1: 0.4852 | \n",
            "Epoch  13/150 | Elapsed Time  67.66 secs | Loss 0.5301  F1 0.4325 | Val th: 0.32  Val F1: 0.4866  Val cw F1: 0.5316 | Test F1: 0.4283  Test cw F1: 0.4659 | Saved for an universal f1 score.\n",
            "Epoch  14/150 | Elapsed Time  66.48 secs | Loss 0.5278  F1 0.4408 | Val th: 0.28  Val F1: 0.4935  Val cw F1: 0.5366 | Test F1: 0.4365  Test cw F1: 0.4691 | Saved for an universal f1 score.\n",
            "Epoch  15/150 | Elapsed Time  74.29 secs | Loss 0.5224  F1 0.4528 | Val th: 0.48  Val F1: 0.5043  Val cw F1: 0.5425 | Test F1: 0.4515  Test cw F1: 0.4977 | Saved for both f1 scores.\n",
            "Epoch  16/150 | Elapsed Time  67.68 secs | Loss 0.5195  F1 0.4590 | Val th: 0.36  Val F1: 0.5209  Val cw F1: 0.5603 | Test F1: 0.4555  Test cw F1: 0.4973 | Saved for an universal f1 score.\n",
            "Epoch  17/150 | Elapsed Time  60.05 secs | Loss 0.5132  F1 0.4659 | Val th: 0.28  Val F1: 0.5315  Val cw F1: 0.5699 | Test F1: 0.4418  Test cw F1: 0.4665 | \n",
            "Epoch  18/150 | Elapsed Time  60.03 secs | Loss 0.5048  F1 0.4799 | Val th: 0.38  Val F1: 0.5395  Val cw F1: 0.5950 | Test F1: 0.4341  Test cw F1: 0.4601 | \n",
            "Epoch  19/150 | Elapsed Time  59.51 secs | Loss 0.4990  F1 0.4891 | Val th: 0.43  Val F1: 0.5438  Val cw F1: 0.5924 | Test F1: 0.4401  Test cw F1: 0.4643 | \n",
            "Epoch  20/150 | Elapsed Time  59.38 secs | Loss 0.4870  F1 0.5117 | Val th: 0.03  Val F1: 0.5695  Val cw F1: 0.6182 | Test F1: 0.4445  Test cw F1: 0.4626 | \n",
            "Epoch  21/150 | Elapsed Time  59.73 secs | Loss 0.4742  F1 0.5280 | Val th: 0.05  Val F1: 0.6032  Val cw F1: 0.6358 | Test F1: 0.4523  Test cw F1: 0.4789 | \n",
            "Epoch  22/150 | Elapsed Time  68.10 secs | Loss 0.4517  F1 0.5541 | Val th: 0.04  Val F1: 0.6079  Val cw F1: 0.6795 | Test F1: 0.4648  Test cw F1: 0.4885 | Saved for an universal f1 score.\n",
            "Epoch  23/150 | Elapsed Time  74.08 secs | Loss 0.4157  F1 0.5864 | Val th: 0.11  Val F1: 0.6772  Val cw F1: 0.7370 | Test F1: 0.4842  Test cw F1: 0.5284 | Saved for both f1 scores.\n",
            "Epoch  24/150 | Elapsed Time  66.81 secs | Loss 0.3670  F1 0.6234 | Val th: 0.11  Val F1: 0.7346  Val cw F1: 0.7657 | Test F1: 0.5170  Test cw F1: 0.5195 | Saved for an universal f1 score.\n",
            "Epoch  25/150 | Elapsed Time  74.85 secs | Loss 0.3343  F1 0.6520 | Val th: 0.50  Val F1: 0.7843  Val cw F1: 0.7899 | Test F1: 0.5249  Test cw F1: 0.5335 | Saved for both f1 scores.\n",
            "Epoch  26/150 | Elapsed Time  74.18 secs | Loss 0.3108  F1 0.6709 | Val th: 0.49  Val F1: 0.8036  Val cw F1: 0.8071 | Test F1: 0.5368  Test cw F1: 0.5419 | Saved for both f1 scores.\n",
            "Epoch  27/150 | Elapsed Time  74.54 secs | Loss 0.2931  F1 0.6820 | Val th: 0.48  Val F1: 0.8201  Val cw F1: 0.8263 | Test F1: 0.5539  Test cw F1: 0.5436 | Saved for both f1 scores.\n",
            "Epoch  28/150 | Elapsed Time  74.45 secs | Loss 0.2807  F1 0.6972 | Val th: 0.39  Val F1: 0.8273  Val cw F1: 0.8331 | Test F1: 0.5800  Test cw F1: 0.5797 | Saved for both f1 scores.\n",
            "Epoch  29/150 | Elapsed Time  59.72 secs | Loss 0.2728  F1 0.7085 | Val th: 0.50  Val F1: 0.8263  Val cw F1: 0.8313 | Test F1: 0.5608  Test cw F1: 0.5682 | \n",
            "Epoch  30/150 | Elapsed Time  67.44 secs | Loss 0.2640  F1 0.7124 | Val th: 0.43  Val F1: 0.8388  Val cw F1: 0.8452 | Test F1: 0.5829  Test cw F1: 0.5785 | Saved for an universal f1 score.\n",
            "Epoch  31/150 | Elapsed Time  67.27 secs | Loss 0.2604  F1 0.7141 | Val th: 0.20  Val F1: 0.8472  Val cw F1: 0.8537 | Test F1: 0.5724  Test cw F1: 0.5855 | Saved for a classwise f1 score.\n",
            "Epoch  32/150 | Elapsed Time  67.72 secs | Loss 0.2510  F1 0.7243 | Val th: 0.23  Val F1: 0.8500  Val cw F1: 0.8560 | Test F1: 0.5895  Test cw F1: 0.5802 | Saved for an universal f1 score.\n",
            "Epoch  33/150 | Elapsed Time  73.73 secs | Loss 0.2440  F1 0.7280 | Val th: 0.44  Val F1: 0.8605  Val cw F1: 0.8683 | Test F1: 0.6060  Test cw F1: 0.6074 | Saved for both f1 scores.\n",
            "Epoch  34/150 | Elapsed Time  60.35 secs | Loss 0.2378  F1 0.7409 | Val th: 0.36  Val F1: 0.8671  Val cw F1: 0.8721 | Test F1: 0.6041  Test cw F1: 0.5933 | \n",
            "Epoch  35/150 | Elapsed Time  59.86 secs | Loss 0.2343  F1 0.7432 | Val th: 0.48  Val F1: 0.8735  Val cw F1: 0.8784 | Test F1: 0.6022  Test cw F1: 0.5975 | \n",
            "Epoch  36/150 | Elapsed Time  67.73 secs | Loss 0.2319  F1 0.7417 | Val th: 0.49  Val F1: 0.8803  Val cw F1: 0.8822 | Test F1: 0.6066  Test cw F1: 0.6019 | Saved for an universal f1 score.\n",
            "Epoch  37/150 | Elapsed Time  73.10 secs | Loss 0.2290  F1 0.7455 | Val th: 0.38  Val F1: 0.8759  Val cw F1: 0.8864 | Test F1: 0.6180  Test cw F1: 0.6207 | Saved for both f1 scores.\n",
            "Epoch  38/150 | Elapsed Time  75.03 secs | Loss 0.2210  F1 0.7574 | Val th: 0.50  Val F1: 0.8791  Val cw F1: 0.8826 | Test F1: 0.6206  Test cw F1: 0.6275 | Saved for both f1 scores.\n",
            "Epoch  39/150 | Elapsed Time  60.60 secs | Loss 0.2212  F1 0.7547 | Val th: 0.48  Val F1: 0.8801  Val cw F1: 0.8835 | Test F1: 0.6105  Test cw F1: 0.6082 | \n",
            "Epoch  40/150 | Elapsed Time  59.69 secs | Loss 0.2154  F1 0.7572 | Val th: 0.50  Val F1: 0.8912  Val cw F1: 0.8960 | Test F1: 0.6085  Test cw F1: 0.6115 | \n",
            "Epoch  41/150 | Elapsed Time  59.66 secs | Loss 0.2203  F1 0.7535 | Val th: 0.50  Val F1: 0.8940  Val cw F1: 0.8948 | Test F1: 0.6141  Test cw F1: 0.6110 | \n",
            "Epoch  42/150 | Elapsed Time  67.92 secs | Loss 0.2122  F1 0.7599 | Val th: 0.39  Val F1: 0.8928  Val cw F1: 0.8961 | Test F1: 0.6245  Test cw F1: 0.6271 | Saved for an universal f1 score.\n",
            "Epoch  43/150 | Elapsed Time  67.53 secs | Loss 0.2080  F1 0.7635 | Val th: 0.50  Val F1: 0.8936  Val cw F1: 0.8990 | Test F1: 0.6270  Test cw F1: 0.6245 | Saved for an universal f1 score.\n",
            "Epoch  44/150 | Elapsed Time  59.97 secs | Loss 0.2101  F1 0.7606 | Val th: 0.41  Val F1: 0.8959  Val cw F1: 0.9001 | Test F1: 0.6172  Test cw F1: 0.6136 | \n",
            "Epoch  45/150 | Elapsed Time  67.90 secs | Loss 0.2050  F1 0.7672 | Val th: 0.44  Val F1: 0.8908  Val cw F1: 0.8953 | Test F1: 0.6265  Test cw F1: 0.6291 | Saved for a classwise f1 score.\n",
            "Epoch  46/150 | Elapsed Time  59.68 secs | Loss 0.2056  F1 0.7674 | Val th: 0.46  Val F1: 0.9002  Val cw F1: 0.9014 | Test F1: 0.6071  Test cw F1: 0.6054 | \n",
            "Epoch  47/150 | Elapsed Time  59.70 secs | Loss 0.2072  F1 0.7620 | Val th: 0.48  Val F1: 0.9048  Val cw F1: 0.9059 | Test F1: 0.5999  Test cw F1: 0.6024 | \n",
            "Epoch  48/150 | Elapsed Time  59.90 secs | Loss 0.2007  F1 0.7731 | Val th: 0.50  Val F1: 0.9044  Val cw F1: 0.9064 | Test F1: 0.6167  Test cw F1: 0.6192 | \n",
            "Epoch  49/150 | Elapsed Time  60.83 secs | Loss 0.1989  F1 0.7754 | Val th: 0.33  Val F1: 0.9001  Val cw F1: 0.9038 | Test F1: 0.6221  Test cw F1: 0.6175 | \n",
            "Epoch  50/150 | Elapsed Time  61.77 secs | Loss 0.1961  F1 0.7798 | Val th: 0.48  Val F1: 0.8990  Val cw F1: 0.9019 | Test F1: 0.6140  Test cw F1: 0.6176 | \n",
            "Epoch  51/150 | Elapsed Time  59.89 secs | Loss 0.1955  F1 0.7752 | Val th: 0.48  Val F1: 0.9029  Val cw F1: 0.9069 | Test F1: 0.6013  Test cw F1: 0.6031 | \n",
            "Epoch  52/150 | Elapsed Time  68.06 secs | Loss 0.1901  F1 0.7813 | Val th: 0.42  Val F1: 0.9001  Val cw F1: 0.9045 | Test F1: 0.6325  Test cw F1: 0.6288 | Saved for an universal f1 score.\n",
            "Epoch  53/150 | Elapsed Time  59.96 secs | Loss 0.1896  F1 0.7836 | Val th: 0.35  Val F1: 0.9010  Val cw F1: 0.9028 | Test F1: 0.6147  Test cw F1: 0.6124 | \n",
            "Epoch  54/150 | Elapsed Time  59.79 secs | Loss 0.1892  F1 0.7855 | Val th: 0.37  Val F1: 0.8957  Val cw F1: 0.8982 | Test F1: 0.6139  Test cw F1: 0.6144 | \n",
            "Epoch  55/150 | Elapsed Time  59.71 secs | Loss 0.1867  F1 0.7847 | Val th: 0.43  Val F1: 0.9029  Val cw F1: 0.9054 | Test F1: 0.5926  Test cw F1: 0.6055 | \n",
            "Epoch  56/150 | Elapsed Time  59.68 secs | Loss 0.1873  F1 0.7873 | Val th: 0.50  Val F1: 0.9053  Val cw F1: 0.9068 | Test F1: 0.6238  Test cw F1: 0.6277 | \n",
            "Epoch  57/150 | Elapsed Time  74.40 secs | Loss 0.1837  F1 0.7856 | Val th: 0.50  Val F1: 0.9071  Val cw F1: 0.9095 | Test F1: 0.6394  Test cw F1: 0.6433 | Saved for both f1 scores.\n",
            "Epoch  58/150 | Elapsed Time  66.94 secs | Loss 0.1874  F1 0.7863 | Val th: 0.49  Val F1: 0.9055  Val cw F1: 0.9093 | Test F1: 0.6371  Test cw F1: 0.6502 | Saved for a classwise f1 score.\n",
            "Epoch  59/150 | Elapsed Time  59.52 secs | Loss 0.1824  F1 0.7900 | Val th: 0.47  Val F1: 0.9065  Val cw F1: 0.9109 | Test F1: 0.6176  Test cw F1: 0.6230 | \n",
            "Epoch  60/150 | Elapsed Time  67.16 secs | Loss 0.1828  F1 0.7880 | Val th: 0.41  Val F1: 0.9083  Val cw F1: 0.9125 | Test F1: 0.6400  Test cw F1: 0.6380 | Saved for an universal f1 score.\n",
            "Epoch  61/150 | Elapsed Time  59.53 secs | Loss 0.1829  F1 0.7862 | Val th: 0.48  Val F1: 0.9073  Val cw F1: 0.9098 | Test F1: 0.6134  Test cw F1: 0.6266 | \n",
            "Epoch  62/150 | Elapsed Time  60.08 secs | Loss 0.1833  F1 0.7874 | Val th: 0.41  Val F1: 0.9103  Val cw F1: 0.9150 | Test F1: 0.6135  Test cw F1: 0.6202 | \n",
            "Epoch  63/150 | Elapsed Time  59.61 secs | Loss 0.1768  F1 0.7947 | Val th: 0.50  Val F1: 0.9130  Val cw F1: 0.9158 | Test F1: 0.6016  Test cw F1: 0.6059 | \n",
            "Epoch  64/150 | Elapsed Time  68.27 secs | Loss 0.1780  F1 0.7940 | Val th: 0.47  Val F1: 0.9099  Val cw F1: 0.9126 | Test F1: 0.6475  Test cw F1: 0.6445 | Saved for an universal f1 score.\n",
            "Epoch  65/150 | Elapsed Time  59.98 secs | Loss 0.1746  F1 0.7979 | Val th: 0.39  Val F1: 0.9105  Val cw F1: 0.9127 | Test F1: 0.6390  Test cw F1: 0.6361 | \n",
            "Epoch  66/150 | Elapsed Time  59.89 secs | Loss 0.1758  F1 0.7985 | Val th: 0.40  Val F1: 0.9094  Val cw F1: 0.9140 | Test F1: 0.6341  Test cw F1: 0.6390 | \n",
            "Epoch  67/150 | Elapsed Time  60.33 secs | Loss 0.1735  F1 0.7976 | Val th: 0.29  Val F1: 0.9123  Val cw F1: 0.9156 | Test F1: 0.6136  Test cw F1: 0.6123 | \n",
            "Epoch  68/150 | Elapsed Time  60.05 secs | Loss 0.1765  F1 0.7955 | Val th: 0.25  Val F1: 0.9126  Val cw F1: 0.9152 | Test F1: 0.5939  Test cw F1: 0.6015 | \n",
            "Epoch  69/150 | Elapsed Time  60.13 secs | Loss 0.1715  F1 0.7989 | Val th: 0.47  Val F1: 0.9190  Val cw F1: 0.9206 | Test F1: 0.6066  Test cw F1: 0.6120 | \n",
            "Epoch  70/150 | Elapsed Time  59.58 secs | Loss 0.1700  F1 0.8028 | Val th: 0.37  Val F1: 0.9186  Val cw F1: 0.9216 | Test F1: 0.6336  Test cw F1: 0.6292 | \n",
            "Epoch  71/150 | Elapsed Time  60.01 secs | Loss 0.1729  F1 0.8003 | Val th: 0.49  Val F1: 0.9188  Val cw F1: 0.9209 | Test F1: 0.6352  Test cw F1: 0.6351 | \n",
            "Epoch  72/150 | Elapsed Time  66.55 secs | Loss 0.1742  F1 0.8004 | Val th: 0.49  Val F1: 0.9195  Val cw F1: 0.9220 | Test F1: 0.6448  Test cw F1: 0.6513 | Saved for a classwise f1 score.\n",
            "Epoch  73/150 | Elapsed Time  60.05 secs | Loss 0.1721  F1 0.8015 | Val th: 0.44  Val F1: 0.9209  Val cw F1: 0.9228 | Test F1: 0.6303  Test cw F1: 0.6293 | \n",
            "Epoch  74/150 | Elapsed Time  74.90 secs | Loss 0.1709  F1 0.8017 | Val th: 0.45  Val F1: 0.9190  Val cw F1: 0.9206 | Test F1: 0.6480  Test cw F1: 0.6528 | Saved for both f1 scores.\n",
            "Epoch  75/150 | Elapsed Time  68.82 secs | Loss 0.1700  F1 0.8030 | Val th: 0.25  Val F1: 0.9174  Val cw F1: 0.9208 | Test F1: 0.6490  Test cw F1: 0.6464 | Saved for an universal f1 score.\n",
            "Epoch  76/150 | Elapsed Time  59.10 secs | Loss 0.1707  F1 0.8026 | Val th: 0.48  Val F1: 0.9176  Val cw F1: 0.9204 | Test F1: 0.6267  Test cw F1: 0.6395 | \n",
            "Epoch  77/150 | Elapsed Time  59.64 secs | Loss 0.1679  F1 0.8046 | Val th: 0.32  Val F1: 0.9128  Val cw F1: 0.9154 | Test F1: 0.6104  Test cw F1: 0.6187 | \n",
            "Epoch  78/150 | Elapsed Time  59.67 secs | Loss 0.1672  F1 0.8058 | Val th: 0.47  Val F1: 0.9173  Val cw F1: 0.9194 | Test F1: 0.6105  Test cw F1: 0.6300 | \n",
            "Epoch  79/150 | Elapsed Time  59.85 secs | Loss 0.1643  F1 0.8072 | Val th: 0.47  Val F1: 0.9240  Val cw F1: 0.9277 | Test F1: 0.5994  Test cw F1: 0.6156 | \n",
            "Epoch  80/150 | Elapsed Time  59.77 secs | Loss 0.1612  F1 0.8126 | Val th: 0.50  Val F1: 0.9225  Val cw F1: 0.9266 | Test F1: 0.6155  Test cw F1: 0.6287 | \n",
            "Epoch  81/150 | Elapsed Time  59.82 secs | Loss 0.1646  F1 0.8087 | Val th: 0.47  Val F1: 0.9248  Val cw F1: 0.9269 | Test F1: 0.6238  Test cw F1: 0.6267 | \n",
            "Epoch  82/150 | Elapsed Time  59.54 secs | Loss 0.1615  F1 0.8109 | Val th: 0.34  Val F1: 0.9198  Val cw F1: 0.9227 | Test F1: 0.6161  Test cw F1: 0.6225 | \n",
            "Epoch  83/150 | Elapsed Time  60.97 secs | Loss 0.1642  F1 0.8095 | Val th: 0.43  Val F1: 0.9181  Val cw F1: 0.9213 | Test F1: 0.6164  Test cw F1: 0.6238 | \n",
            "Epoch  84/150 | Elapsed Time  59.97 secs | Loss 0.1605  F1 0.8119 | Val th: 0.20  Val F1: 0.9237  Val cw F1: 0.9254 | Test F1: 0.6382  Test cw F1: 0.6383 | \n",
            "Epoch  85/150 | Elapsed Time  60.51 secs | Loss 0.1604  F1 0.8146 | Val th: 0.39  Val F1: 0.9263  Val cw F1: 0.9293 | Test F1: 0.6287  Test cw F1: 0.6279 | \n",
            "Epoch  86/150 | Elapsed Time  59.88 secs | Loss 0.1628  F1 0.8083 | Val th: 0.50  Val F1: 0.9263  Val cw F1: 0.9279 | Test F1: 0.6157  Test cw F1: 0.6289 | \n",
            "Epoch  87/150 | Elapsed Time  60.06 secs | Loss 0.1620  F1 0.8105 | Val th: 0.34  Val F1: 0.9232  Val cw F1: 0.9250 | Test F1: 0.6470  Test cw F1: 0.6522 | \n",
            "Epoch  88/150 | Elapsed Time  59.87 secs | Loss 0.1618  F1 0.8093 | Val th: 0.50  Val F1: 0.9217  Val cw F1: 0.9222 | Test F1: 0.6401  Test cw F1: 0.6402 | \n",
            "Epoch  89/150 | Elapsed Time  60.12 secs | Loss 0.1590  F1 0.8129 | Val th: 0.43  Val F1: 0.9216  Val cw F1: 0.9225 | Test F1: 0.6482  Test cw F1: 0.6477 | \n",
            "Epoch  90/150 | Elapsed Time  59.26 secs | Loss 0.1565  F1 0.8199 | Val th: 0.37  Val F1: 0.9272  Val cw F1: 0.9288 | Test F1: 0.6446  Test cw F1: 0.6471 | \n",
            "Epoch  91/150 | Elapsed Time  67.03 secs | Loss 0.1577  F1 0.8165 | Val th: 0.50  Val F1: 0.9239  Val cw F1: 0.9247 | Test F1: 0.6517  Test cw F1: 0.6456 | Saved for an universal f1 score.\n",
            "Epoch  92/150 | Elapsed Time  59.54 secs | Loss 0.1596  F1 0.8137 | Val th: 0.37  Val F1: 0.9220  Val cw F1: 0.9229 | Test F1: 0.6395  Test cw F1: 0.6505 | \n",
            "Epoch  93/150 | Elapsed Time  58.86 secs | Loss 0.1559  F1 0.8172 | Val th: 0.46  Val F1: 0.9213  Val cw F1: 0.9228 | Test F1: 0.6386  Test cw F1: 0.6477 | \n",
            "Epoch  94/150 | Elapsed Time  59.60 secs | Loss 0.1604  F1 0.8125 | Val th: 0.50  Val F1: 0.9257  Val cw F1: 0.9265 | Test F1: 0.6345  Test cw F1: 0.6465 | \n",
            "Epoch  95/150 | Elapsed Time  59.11 secs | Loss 0.1589  F1 0.8132 | Val th: 0.37  Val F1: 0.9343  Val cw F1: 0.9360 | Test F1: 0.6427  Test cw F1: 0.6469 | \n",
            "Epoch  96/150 | Elapsed Time  59.35 secs | Loss 0.1520  F1 0.8191 | Val th: 0.38  Val F1: 0.9333  Val cw F1: 0.9353 | Test F1: 0.6298  Test cw F1: 0.6432 | \n",
            "Epoch  97/150 | Elapsed Time  59.26 secs | Loss 0.1564  F1 0.8149 | Val th: 0.50  Val F1: 0.9317  Val cw F1: 0.9336 | Test F1: 0.6035  Test cw F1: 0.6341 | \n",
            "Epoch  98/150 | Elapsed Time  59.59 secs | Loss 0.1553  F1 0.8175 | Val th: 0.45  Val F1: 0.9338  Val cw F1: 0.9363 | Test F1: 0.6320  Test cw F1: 0.6371 | \n",
            "Epoch  99/150 | Elapsed Time  59.43 secs | Loss 0.1533  F1 0.8184 | Val th: 0.49  Val F1: 0.9343  Val cw F1: 0.9351 | Test F1: 0.6249  Test cw F1: 0.6299 | \n",
            "Epoch 100/150 | Elapsed Time  59.05 secs | Loss 0.1577  F1 0.8164 | Val th: 0.48  Val F1: 0.9339  Val cw F1: 0.9340 | Test F1: 0.6186  Test cw F1: 0.6381 | \n",
            "Epoch 101/150 | Elapsed Time  59.38 secs | Loss 0.1556  F1 0.8191 | Val th: 0.45  Val F1: 0.9348  Val cw F1: 0.9349 | Test F1: 0.6201  Test cw F1: 0.6328 | \n",
            "Epoch 102/150 | Elapsed Time  59.88 secs | Loss 0.1515  F1 0.8198 | Val th: 0.50  Val F1: 0.9339  Val cw F1: 0.9358 | Test F1: 0.6220  Test cw F1: 0.6449 | \n",
            "Epoch 103/150 | Elapsed Time  59.94 secs | Loss 0.1514  F1 0.8219 | Val th: 0.46  Val F1: 0.9335  Val cw F1: 0.9342 | Test F1: 0.6347  Test cw F1: 0.6350 | \n",
            "Epoch 104/150 | Elapsed Time  59.19 secs | Loss 0.1517  F1 0.8219 | Val th: 0.45  Val F1: 0.9345  Val cw F1: 0.9361 | Test F1: 0.6194  Test cw F1: 0.6260 | \n",
            "Epoch 105/150 | Elapsed Time  59.44 secs | Loss 0.1533  F1 0.8204 | Val th: 0.46  Val F1: 0.9342  Val cw F1: 0.9367 | Test F1: 0.6336  Test cw F1: 0.6456 | \n",
            "Epoch 106/150 | Elapsed Time  60.63 secs | Loss 0.1510  F1 0.8193 | Val th: 0.43  Val F1: 0.9340  Val cw F1: 0.9370 | Test F1: 0.6425  Test cw F1: 0.6507 | \n",
            "Epoch 107/150 | Elapsed Time  60.72 secs | Loss 0.1560  F1 0.8177 | Val th: 0.48  Val F1: 0.9330  Val cw F1: 0.9338 | Test F1: 0.6397  Test cw F1: 0.6444 | \n",
            "Epoch 108/150 | Elapsed Time  60.16 secs | Loss 0.1504  F1 0.8211 | Val th: 0.47  Val F1: 0.9338  Val cw F1: 0.9348 | Test F1: 0.6398  Test cw F1: 0.6428 | \n",
            "Epoch 109/150 | Elapsed Time  59.88 secs | Loss 0.1517  F1 0.8210 | Val th: 0.48  Val F1: 0.9354  Val cw F1: 0.9356 | Test F1: 0.6305  Test cw F1: 0.6361 | \n",
            "Epoch 110/150 | Elapsed Time  59.66 secs | Loss 0.1516  F1 0.8218 | Val th: 0.47  Val F1: 0.9354  Val cw F1: 0.9360 | Test F1: 0.6391  Test cw F1: 0.6442 | \n",
            "Epoch 111/150 | Elapsed Time  59.89 secs | Loss 0.1498  F1 0.8240 | Val th: 0.43  Val F1: 0.9358  Val cw F1: 0.9364 | Test F1: 0.6472  Test cw F1: 0.6481 | \n",
            "Epoch 112/150 | Elapsed Time  60.16 secs | Loss 0.1515  F1 0.8234 | Val th: 0.33  Val F1: 0.9363  Val cw F1: 0.9364 | Test F1: 0.6471  Test cw F1: 0.6442 | \n",
            "Epoch 113/150 | Elapsed Time  67.81 secs | Loss 0.1525  F1 0.8223 | Val th: 0.37  Val F1: 0.9374  Val cw F1: 0.9388 | Test F1: 0.6513  Test cw F1: 0.6529 | Saved for a classwise f1 score.\n",
            "Epoch 114/150 | Elapsed Time  74.20 secs | Loss 0.1503  F1 0.8220 | Val th: 0.42  Val F1: 0.9353  Val cw F1: 0.9375 | Test F1: 0.6517  Test cw F1: 0.6562 | Saved for both f1 scores.\n",
            "Epoch 115/150 | Elapsed Time  59.20 secs | Loss 0.1507  F1 0.8220 | Val th: 0.40  Val F1: 0.9346  Val cw F1: 0.9354 | Test F1: 0.6476  Test cw F1: 0.6538 | \n",
            "Epoch 116/150 | Elapsed Time  59.97 secs | Loss 0.1495  F1 0.8234 | Val th: 0.41  Val F1: 0.9357  Val cw F1: 0.9359 | Test F1: 0.6455  Test cw F1: 0.6490 | \n",
            "Epoch 117/150 | Elapsed Time  59.75 secs | Loss 0.1475  F1 0.8256 | Val th: 0.47  Val F1: 0.9371  Val cw F1: 0.9383 | Test F1: 0.6403  Test cw F1: 0.6497 | \n",
            "Epoch 118/150 | Elapsed Time  59.97 secs | Loss 0.1496  F1 0.8229 | Val th: 0.50  Val F1: 0.9369  Val cw F1: 0.9392 | Test F1: 0.6377  Test cw F1: 0.6497 | \n",
            "Epoch 119/150 | Elapsed Time  59.82 secs | Loss 0.1500  F1 0.8244 | Val th: 0.45  Val F1: 0.9363  Val cw F1: 0.9372 | Test F1: 0.6469  Test cw F1: 0.6533 | \n",
            "Epoch 120/150 | Elapsed Time  60.33 secs | Loss 0.1500  F1 0.8241 | Val th: 0.22  Val F1: 0.9357  Val cw F1: 0.9382 | Test F1: 0.6474  Test cw F1: 0.6510 | \n",
            "Epoch 121/150 | Elapsed Time  60.00 secs | Loss 0.1488  F1 0.8238 | Val th: 0.46  Val F1: 0.9353  Val cw F1: 0.9383 | Test F1: 0.6458  Test cw F1: 0.6497 | \n",
            "Epoch 122/150 | Elapsed Time  60.04 secs | Loss 0.1498  F1 0.8236 | Val th: 0.43  Val F1: 0.9345  Val cw F1: 0.9375 | Test F1: 0.6447  Test cw F1: 0.6481 | \n",
            "Epoch 123/150 | Elapsed Time  59.28 secs | Loss 0.1517  F1 0.8210 | Val th: 0.50  Val F1: 0.9361  Val cw F1: 0.9380 | Test F1: 0.6391  Test cw F1: 0.6442 | \n",
            "Epoch 124/150 | Elapsed Time  59.83 secs | Loss 0.1515  F1 0.8190 | Val th: 0.45  Val F1: 0.9349  Val cw F1: 0.9373 | Test F1: 0.6408  Test cw F1: 0.6499 | \n",
            "Epoch 125/150 | Elapsed Time  59.31 secs | Loss 0.1468  F1 0.8259 | Val th: 0.48  Val F1: 0.9348  Val cw F1: 0.9373 | Test F1: 0.6392  Test cw F1: 0.6524 | \n",
            "Epoch 126/150 | Elapsed Time  59.56 secs | Loss 0.1495  F1 0.8214 | Val th: 0.41  Val F1: 0.9350  Val cw F1: 0.9376 | Test F1: 0.6496  Test cw F1: 0.6480 | \n",
            "Epoch 127/150 | Elapsed Time  59.86 secs | Loss 0.1509  F1 0.8211 | Val th: 0.49  Val F1: 0.9345  Val cw F1: 0.9370 | Test F1: 0.6395  Test cw F1: 0.6435 | \n",
            "Epoch 128/150 | Elapsed Time  59.88 secs | Loss 0.1485  F1 0.8251 | Val th: 0.47  Val F1: 0.9343  Val cw F1: 0.9368 | Test F1: 0.6373  Test cw F1: 0.6421 | \n",
            "Epoch 129/150 | Elapsed Time  59.17 secs | Loss 0.1486  F1 0.8215 | Val th: 0.49  Val F1: 0.9357  Val cw F1: 0.9376 | Test F1: 0.6359  Test cw F1: 0.6439 | \n",
            "Epoch 130/150 | Elapsed Time  59.67 secs | Loss 0.1490  F1 0.8228 | Val th: 0.50  Val F1: 0.9353  Val cw F1: 0.9373 | Test F1: 0.6352  Test cw F1: 0.6448 | \n",
            "Epoch 131/150 | Elapsed Time  59.82 secs | Loss 0.1481  F1 0.8254 | Val th: 0.48  Val F1: 0.9357  Val cw F1: 0.9376 | Test F1: 0.6365  Test cw F1: 0.6480 | \n",
            "Epoch 132/150 | Elapsed Time  59.59 secs | Loss 0.1462  F1 0.8280 | Val th: 0.49  Val F1: 0.9362  Val cw F1: 0.9380 | Test F1: 0.6366  Test cw F1: 0.6490 | \n",
            "Epoch 133/150 | Elapsed Time  59.56 secs | Loss 0.1487  F1 0.8238 | Val th: 0.50  Val F1: 0.9357  Val cw F1: 0.9376 | Test F1: 0.6368  Test cw F1: 0.6460 | \n",
            "Epoch 134/150 | Elapsed Time  59.71 secs | Loss 0.1480  F1 0.8251 | Val th: 0.49  Val F1: 0.9348  Val cw F1: 0.9367 | Test F1: 0.6322  Test cw F1: 0.6470 | \n",
            "Epoch 135/150 | Elapsed Time  59.85 secs | Loss 0.1485  F1 0.8261 | Val th: 0.47  Val F1: 0.9338  Val cw F1: 0.9369 | Test F1: 0.6356  Test cw F1: 0.6472 | \n",
            "Epoch 136/150 | Elapsed Time  59.82 secs | Loss 0.1488  F1 0.8247 | Val th: 0.50  Val F1: 0.9336  Val cw F1: 0.9357 | Test F1: 0.6350  Test cw F1: 0.6516 | \n",
            "Epoch 137/150 | Elapsed Time  59.87 secs | Loss 0.1437  F1 0.8305 | Val th: 0.50  Val F1: 0.9358  Val cw F1: 0.9377 | Test F1: 0.6360  Test cw F1: 0.6489 | \n",
            "Epoch 138/150 | Elapsed Time  59.59 secs | Loss 0.1486  F1 0.8266 | Val th: 0.49  Val F1: 0.9372  Val cw F1: 0.9392 | Test F1: 0.6350  Test cw F1: 0.6508 | \n",
            "Epoch 139/150 | Elapsed Time  59.21 secs | Loss 0.1484  F1 0.8256 | Val th: 0.49  Val F1: 0.9372  Val cw F1: 0.9391 | Test F1: 0.6356  Test cw F1: 0.6512 | \n",
            "Epoch 140/150 | Elapsed Time  59.74 secs | Loss 0.1471  F1 0.8288 | Val th: 0.49  Val F1: 0.9372  Val cw F1: 0.9391 | Test F1: 0.6345  Test cw F1: 0.6455 | \n",
            "Epoch 141/150 | Elapsed Time  60.09 secs | Loss 0.1461  F1 0.8231 | Val th: 0.49  Val F1: 0.9358  Val cw F1: 0.9377 | Test F1: 0.6341  Test cw F1: 0.6489 | \n",
            "Epoch 142/150 | Elapsed Time  59.91 secs | Loss 0.1476  F1 0.8265 | Val th: 0.50  Val F1: 0.9358  Val cw F1: 0.9377 | Test F1: 0.6325  Test cw F1: 0.6496 | \n",
            "Epoch 143/150 | Elapsed Time  60.13 secs | Loss 0.1450  F1 0.8240 | Val th: 0.47  Val F1: 0.9353  Val cw F1: 0.9373 | Test F1: 0.6327  Test cw F1: 0.6499 | \n",
            "Epoch 144/150 | Elapsed Time  60.05 secs | Loss 0.1488  F1 0.8237 | Val th: 0.49  Val F1: 0.9357  Val cw F1: 0.9382 | Test F1: 0.6329  Test cw F1: 0.6487 | \n",
            "Epoch 145/150 | Elapsed Time  60.70 secs | Loss 0.1471  F1 0.8262 | Val th: 0.48  Val F1: 0.9357  Val cw F1: 0.9382 | Test F1: 0.6352  Test cw F1: 0.6510 | \n",
            "Epoch 146/150 | Elapsed Time  59.68 secs | Loss 0.1486  F1 0.8244 | Val th: 0.49  Val F1: 0.9357  Val cw F1: 0.9378 | Test F1: 0.6336  Test cw F1: 0.6490 | \n",
            "Epoch 147/150 | Elapsed Time  59.78 secs | Loss 0.1450  F1 0.8285 | Val th: 0.49  Val F1: 0.9352  Val cw F1: 0.9378 | Test F1: 0.6324  Test cw F1: 0.6485 | \n",
            "Epoch 148/150 | Elapsed Time  59.40 secs | Loss 0.1478  F1 0.8229 | Val th: 0.50  Val F1: 0.9352  Val cw F1: 0.9378 | Test F1: 0.6337  Test cw F1: 0.6488 | \n",
            "Epoch 149/150 | Elapsed Time  59.79 secs | Loss 0.1495  F1 0.8256 | Val th: 0.48  Val F1: 0.9352  Val cw F1: 0.9378 | Test F1: 0.6336  Test cw F1: 0.6486 | \n",
            "Epoch 150/150 | Elapsed Time  59.82 secs | Loss 0.1497  F1 0.8242 | Val th: 0.50  Val F1: 0.9352  Val cw F1: 0.9378 | Test F1: 0.6323  Test cw F1: 0.6460 | \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6517441047661832, 0.6562085534607675)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M79JA4nieZ7F"
      },
      "source": [
        "# Post optimization process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8gZiAKDeKgG"
      },
      "source": [
        "## Find best crop ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HbjLEzsrv-a"
      },
      "source": [
        "# crop_ratios = np.linspace(0.5, 0.9, num=20)\n",
        "# for cr in crop_ratios:\n",
        "#   cropped_valid_data = load_data(DATA_DIR,\n",
        "#                                 is_train=False,\n",
        "#                                 crop_ratio=cr,\n",
        "#                                 strategy=strategy)\n",
        "#   print(f'CR: {cr}', evaluate(cropped_valid_data, 0.1733467))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cr3qhn4eeD5"
      },
      "source": [
        "## Find best classwise thresholds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_3pTtVpjGOR"
      },
      "source": [
        "# y_trues, y_logits = get_prediction(valid_data)\n",
        "# y_probs = tf.nn.sigmoid(y_logits)\n",
        "# thresholds = np.linspace(0., 0.5, num=500, dtype='float32')\n",
        "# ths = []\n",
        "# ss = []\n",
        "# for i in range(7):\n",
        "#   y_prob = y_probs[:,i]\n",
        "#   y_true = y_trues[:,i]\n",
        "\n",
        "#   best_threshold = 0\n",
        "#   best_score = 0  \n",
        "#   for threshold in thresholds:\n",
        "#     y_pred = tf.where(y_prob >= threshold, 1.0, 0.0)\n",
        "#     np_y_true = y_true.numpy()\n",
        "#     np_y_pred = y_pred.numpy()\n",
        "#     score = f1_score(np_y_true, np_y_pred)\n",
        "#     if best_score < score:\n",
        "#       best_threshold = threshold\n",
        "#       best_score = score\n",
        "#   ths.append(best_threshold)\n",
        "#   ss.append(best_score)\n",
        "\n",
        "# print(np.mean(ss))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}